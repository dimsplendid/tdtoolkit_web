{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "import sqlalchemy as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# fitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "# check\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC = \"LCT-19-580\"\n",
    "url = \"sqlite:///../database/demo.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "engine = sql.create_engine(url, echo=False)\n",
    "\n",
    "opt = pd.read_sql(f'SELECT ID, Point as point, Voltage/2 as Vop, \"LCM_Y%\" as \"LC%\" FROM opt WHERE LC == \"{LC}\"', engine)\n",
    "cell_gap = pd.read_sql(f'SELECT ID, Point as point, \"cell gap\" FROM axo WHERE LC == \"{LC}\"', engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>point</th>\n",
       "      <th>Vop</th>\n",
       "      <th>LC%</th>\n",
       "      <th>cell gap</th>\n",
       "      <th>T%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T108C001NM21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>2.268366</td>\n",
       "      <td>0.008135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T108C001NM21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>2.268366</td>\n",
       "      <td>0.014962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T108C001NM21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>2.268366</td>\n",
       "      <td>0.009006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T108C001NM21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>2.268366</td>\n",
       "      <td>0.028326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T108C001NM21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>2.268366</td>\n",
       "      <td>0.075973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>T108C001NM2K</td>\n",
       "      <td>6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.797783</td>\n",
       "      <td>2.519869</td>\n",
       "      <td>98.808158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>T108C001NM2K</td>\n",
       "      <td>6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.794256</td>\n",
       "      <td>2.519869</td>\n",
       "      <td>98.371327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>T108C001NM2K</td>\n",
       "      <td>6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.793753</td>\n",
       "      <td>2.519869</td>\n",
       "      <td>98.309029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>T108C001NM2K</td>\n",
       "      <td>6</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.791212</td>\n",
       "      <td>2.519869</td>\n",
       "      <td>97.994318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>T108C001NM2K</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.785286</td>\n",
       "      <td>2.519869</td>\n",
       "      <td>97.260362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3060 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  point   Vop       LC%  cell gap         T%\n",
       "0     T108C001NM21      1   0.0  0.000056  2.268366   0.008135\n",
       "1     T108C001NM21      1   0.2  0.000103  2.268366   0.014962\n",
       "2     T108C001NM21      1   0.4  0.000062  2.268366   0.009006\n",
       "3     T108C001NM21      1   0.6  0.000195  2.268366   0.028326\n",
       "4     T108C001NM21      1   0.8  0.000523  2.268366   0.075973\n",
       "...            ...    ...   ...       ...       ...        ...\n",
       "3055  T108C001NM2K      6   9.2  0.797783  2.519869  98.808158\n",
       "3056  T108C001NM2K      6   9.4  0.794256  2.519869  98.371327\n",
       "3057  T108C001NM2K      6   9.6  0.793753  2.519869  98.309029\n",
       "3058  T108C001NM2K      6   9.8  0.791212  2.519869  97.994318\n",
       "3059  T108C001NM2K      6  10.0  0.785286  2.519869  97.260362\n",
       "\n",
       "[3060 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = pd.merge(opt, cell_gap, how=\"left\", on=[\"ID\", \"point\"])\n",
    "opt[\"T%\"] = opt.groupby(by=[\"ID\", \"point\"])[\"LC%\"].apply(lambda x: 100*x / float(x.max()))\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test draw\n",
    "tmp_df = opt[(opt[\"ID\"] == \"T108C001NM2Q\") & (opt[\"point\"] == 1)][[\"Vop\", \"T%\"]]\n",
    "plt.scatter(tmp_df[\"Vop\"], tmp_df[\"T%\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "df = opt[[\"Vop\", \"cell gap\", \"T%\"]].to_numpy()\n",
    "training_set, test_set = train_test_split(\n",
    "    df,\n",
    "    test_size = 0.2,\n",
    "#     random_state = 42\n",
    ")\n",
    "X_train = training_set[:,:-1]\n",
    "y_train = training_set[:,-1]\n",
    "X_test = test_set[:,:-1]\n",
    "y_test = test_set[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"linear_regression\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "normalization_3 (Normalizati (None, 2)                 5         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 82\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(num_features,), name=\"input_layer\")\n",
    "x = preprocessing.Normalization()(inputs)\n",
    "x = Dense(3, use_bias=True, activation='sigmoid', name='dense1')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(6, use_bias=True, activation='relu', name='dense2')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(3, use_bias=True, activation='relu', name='dense3')(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(1, activation='linear', name=\"output\")(x)\n",
    "\n",
    "model = Model(inputs, outputs, name='linear_regression')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001 # 初始化學習率\n",
    "    drop = 0.8 # 每次遞減率\n",
    "    epochs_drop = 20 # 每 100 個 epochs 降低一次學習率\n",
    "    lrate = initial_lrate * tf.math.pow(drop, tf.math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "# 建立 LearningRateScheduler\n",
    "lr_schedule = LearningRateScheduler(step_decay, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 6103.5869 - val_loss: 6430.1699\n",
      "Epoch 2/2000\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6055.2051 - val_loss: 6396.8408\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 6010.9590 - val_loss: 6360.2192\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5959.5278 - val_loss: 6321.3677\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5899.8740 - val_loss: 6259.2192\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5836.5601 - val_loss: 6201.7012\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 5746.6616 - val_loss: 6129.9961\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 5634.4517 - val_loss: 6041.8979\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5494.3130 - val_loss: 5931.8657\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5324.0571 - val_loss: 5793.5098\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5113.4653 - val_loss: 5617.4570\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4871.3511 - val_loss: 5485.0532\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4675.0713 - val_loss: 5191.4448\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4423.5181 - val_loss: 5024.3809\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3863.4431 - val_loss: 4877.3252\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3519.9443 - val_loss: 4234.8340\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2955.3357 - val_loss: 4235.0557\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 2417.3494 - val_loss: 4148.4678\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1892.6122 - val_loss: 3975.0947\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1411.3916 - val_loss: 3691.2749\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1077.1868 - val_loss: 3403.9248\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 794.8834 - val_loss: 3162.0215\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 567.6335 - val_loss: 2949.8342\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 393.0876 - val_loss: 2748.9519\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 264.8035 - val_loss: 2567.2002\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 174.1810 - val_loss: 2375.7769\n",
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 112.4199 - val_loss: 2252.6372\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 71.8204 - val_loss: 2016.9441\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 46.8240 - val_loss: 2181.5935\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 42.1510 - val_loss: 1409.4415\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 126.2844 - val_loss: 4894.5532\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 502.0770 - val_loss: 726.5815\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 315.9581 - val_loss: 2232.2068\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 92.5171 - val_loss: 783.6514\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 42.4899 - val_loss: 1082.8097\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 30.4644 - val_loss: 694.4871\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 27.1733 - val_loss: 897.2952\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 26.9253 - val_loss: 711.5823\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(0.00080000004, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 24.1225 - val_loss: 776.0225\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 22.7151 - val_loss: 687.0733\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 17.9871 - val_loss: 676.9854\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 15.7727 - val_loss: 686.3145\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 14.5796 - val_loss: 676.1398\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 13.7841 - val_loss: 692.4678\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 13.2059 - val_loss: 685.2312\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 12.7537 - val_loss: 698.4799\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 12.3657 - val_loss: 694.0885\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 12.0247 - val_loss: 704.8070\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 11.7127 - val_loss: 701.7095\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 11.4252 - val_loss: 709.9235\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 11.1586 - val_loss: 708.3569\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 10.9060 - val_loss: 714.9876\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 10.6677 - val_loss: 714.4094\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 10.4427 - val_loss: 719.7764\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 10.2350 - val_loss: 718.3512\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 10.0471 - val_loss: 723.1282\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.8678 - val_loss: 722.8258\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.6957 - val_loss: 726.9762\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006400001, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.5304 - val_loss: 727.5059\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.3711 - val_loss: 729.9111\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 9.2477 - val_loss: 730.7990\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 9.1282 - val_loss: 732.1969\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 9.0119 - val_loss: 732.7645\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 8.8984 - val_loss: 733.3910\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 8.7878 - val_loss: 734.2396\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 8.6788 - val_loss: 735.3339\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.5721 - val_loss: 736.3084\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.4677 - val_loss: 736.5250\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.3670 - val_loss: 737.1577\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.2691 - val_loss: 737.3866\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 8.1742 - val_loss: 737.6218\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 8.0827 - val_loss: 737.0325\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.9958 - val_loss: 736.1384\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.9135 - val_loss: 734.6032\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.8349 - val_loss: 733.2111\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.7591 - val_loss: 731.9453\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.6849 - val_loss: 730.5585\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.6124 - val_loss: 729.4794\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to tf.Tensor(0.00051200006, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.5412 - val_loss: 728.2327\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.4712 - val_loss: 726.8365\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.4161 - val_loss: 725.6272\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.3615 - val_loss: 724.3104\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.3074 - val_loss: 722.8400\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2540 - val_loss: 721.5073\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.2012 - val_loss: 719.9877\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 7.1492 - val_loss: 718.6500\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.0975 - val_loss: 717.3254\n",
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.0462 - val_loss: 715.9797\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.9951 - val_loss: 714.8333\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.9440 - val_loss: 713.4182\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.8932 - val_loss: 711.9811\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.8428 - val_loss: 710.3298\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.7930 - val_loss: 708.8068\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.7438 - val_loss: 707.2439\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.6950 - val_loss: 705.6446\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.646 - 0s 25ms/step - loss: 6.6467 - val_loss: 704.1688\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.5987 - val_loss: 702.4952\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.5512 - val_loss: 700.8448\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to tf.Tensor(0.00040960003, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.5042 - val_loss: 699.1192\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 6.4577 - val_loss: 697.2397\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.4208 - val_loss: 695.3379\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.3842 - val_loss: 693.4031\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.3479 - val_loss: 691.4354\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 6.3119 - val_loss: 689.4597\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.2761 - val_loss: 687.4497\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.2406 - val_loss: 685.3859\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.2053 - val_loss: 683.3643\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.1702 - val_loss: 681.3032\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 6.1353 - val_loss: 679.2498\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.1006 - val_loss: 677.1548\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 6.0660 - val_loss: 674.9716\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 6.0316 - val_loss: 672.7458\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.9975 - val_loss: 670.5323\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.9637 - val_loss: 668.2502\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.9301 - val_loss: 665.9473\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.8968 - val_loss: 663.6412\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.8637 - val_loss: 661.2974\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.8308 - val_loss: 658.9225\n",
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to tf.Tensor(0.00032768, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.7982 - val_loss: 656.5144\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.7659 - val_loss: 654.0189\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.7402 - val_loss: 651.4614\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.7147 - val_loss: 648.9073\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.6893 - val_loss: 646.3701\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.6640 - val_loss: 643.8191\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.6388 - val_loss: 641.2408\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.6138 - val_loss: 638.6932\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.5887 - val_loss: 636.1413\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.5636 - val_loss: 633.6103\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.5385 - val_loss: 630.9577\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.5135 - val_loss: 628.2979\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.4886 - val_loss: 625.6389\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.4638 - val_loss: 622.9429\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.4390 - val_loss: 620.2206\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.4144 - val_loss: 617.4680\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 5.3899 - val_loss: 614.6971\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.3656 - val_loss: 611.9117\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.3414 - val_loss: 609.1073\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.3173 - val_loss: 606.2697\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to tf.Tensor(0.00026214405, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.2935 - val_loss: 603.4395\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.2698 - val_loss: 600.5277\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.2509 - val_loss: 597.5596\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.2322 - val_loss: 594.5806\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.2137 - val_loss: 591.5933\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.1952 - val_loss: 588.5660\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.1770 - val_loss: 585.5040\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.1589 - val_loss: 582.4498\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.1409 - val_loss: 579.4379\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1230 - val_loss: 576.4373\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.1052 - val_loss: 573.4392\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0875 - val_loss: 570.4395\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 5.0698 - val_loss: 567.4352\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0523 - val_loss: 564.4280\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0348 - val_loss: 561.4169\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 5.0174 - val_loss: 558.4011\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 5.0000 - val_loss: 555.3813\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.9828 - val_loss: 552.3574\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.9656 - val_loss: 549.3295\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.9485 - val_loss: 546.2986\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020971522, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.9315 - val_loss: 543.2648\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.9145 - val_loss: 540.1680\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.9010 - val_loss: 537.0691\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.8876 - val_loss: 533.9686\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.8742 - val_loss: 530.8679\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.8608 - val_loss: 527.7665\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8475 - val_loss: 524.6630\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8343 - val_loss: 521.5605\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8210 - val_loss: 518.4572\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8079 - val_loss: 515.3367\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7948 - val_loss: 512.2239\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 4.7817 - val_loss: 509.1171\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.7687 - val_loss: 506.0042\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7558 - val_loss: 502.8750\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.7429 - val_loss: 499.7582\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7300 - val_loss: 496.6477\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7172 - val_loss: 493.5407\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.7045 - val_loss: 490.4352\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.6918 - val_loss: 487.3278\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.6791 - val_loss: 484.2238\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to tf.Tensor(0.00016777219, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.6665 - val_loss: 481.1227\n",
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.6539 - val_loss: 477.9736\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.6439 - val_loss: 474.8269\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.6339 - val_loss: 471.6823\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.6240 - val_loss: 468.5415\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.6140 - val_loss: 465.4040\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.6041 - val_loss: 462.2728\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.5942 - val_loss: 459.1429\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.5844 - val_loss: 456.0164\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5745 - val_loss: 452.8940\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5647 - val_loss: 449.7753\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5549 - val_loss: 446.6606\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.5452 - val_loss: 443.5494\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.5355 - val_loss: 440.4313\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.5258 - val_loss: 437.3215\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.5161 - val_loss: 434.2188\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.5065 - val_loss: 431.1223\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.4969 - val_loss: 428.0310\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4873 - val_loss: 424.9458\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4778 - val_loss: 421.8653\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013421774, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4682 - val_loss: 418.7839\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.4588 - val_loss: 415.6714\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4512 - val_loss: 412.5665\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4436 - val_loss: 409.4681\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.4361 - val_loss: 406.3757\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.4285 - val_loss: 403.2876\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4210 - val_loss: 400.2085\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.4135 - val_loss: 397.1310\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.4061 - val_loss: 394.0643\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.3986 - val_loss: 391.0060\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3912 - val_loss: 387.9640\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.3837 - val_loss: 384.9258\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.3763 - val_loss: 381.8949\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3689 - val_loss: 378.8748\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 4.3615 - val_loss: 375.8605\n",
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3541 - val_loss: 372.8579\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.3468 - val_loss: 369.8622\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.3394 - val_loss: 366.8709\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3321 - val_loss: 363.9030\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3247 - val_loss: 360.9379\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001073742, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3174 - val_loss: 357.9834\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.3100 - val_loss: 354.9926\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.3042 - val_loss: 352.0107\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.2983 - val_loss: 349.0317\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.2925 - val_loss: 346.0613\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2866 - val_loss: 343.0996\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.2808 - val_loss: 340.1471\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2750 - val_loss: 337.2071\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2692 - val_loss: 334.2757\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2634 - val_loss: 331.3534\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2576 - val_loss: 328.4406\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.2519 - val_loss: 325.5373\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2461 - val_loss: 322.6438\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2403 - val_loss: 319.7556\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.2346 - val_loss: 316.8784\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2289 - val_loss: 314.0155\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.2232 - val_loss: 311.1629\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.2175 - val_loss: 308.3182\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.2118 - val_loss: 305.4858\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.2061 - val_loss: 302.6646\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: LearningRateScheduler reducing learning rate to tf.Tensor(8.5899366e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 4.2004 - val_loss: 299.8536\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1948 - val_loss: 297.0251\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1903 - val_loss: 294.2090\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.1858 - val_loss: 291.4051\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1812 - val_loss: 288.6166\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1767 - val_loss: 285.8594\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.1722 - val_loss: 283.1600\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1678 - val_loss: 280.5354\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.1633 - val_loss: 277.9558\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1588 - val_loss: 275.4164\n",
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.1543 - val_loss: 272.8877\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.1498 - val_loss: 270.3808\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1454 - val_loss: 267.9094\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1409 - val_loss: 265.4644\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1365 - val_loss: 263.0560\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.1321 - val_loss: 260.6898\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.1276 - val_loss: 258.3671\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1232 - val_loss: 256.0648\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1188 - val_loss: 253.7903\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1144 - val_loss: 251.5296\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: LearningRateScheduler reducing learning rate to tf.Tensor(6.871949e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1100 - val_loss: 249.2740\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.1056 - val_loss: 247.0088\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.1021 - val_loss: 244.7564\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0986 - val_loss: 242.5292\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0951 - val_loss: 240.3151\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0916 - val_loss: 238.1228\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 4.0882 - val_loss: 235.9434\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0847 - val_loss: 233.7841\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0812 - val_loss: 231.6486\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0778 - val_loss: 229.5505\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.0743 - val_loss: 227.4770\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0708 - val_loss: 225.4278\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0674 - val_loss: 223.3927\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0639 - val_loss: 221.3748\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0605 - val_loss: 219.3664\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0570 - val_loss: 217.3673\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 4.0536 - val_loss: 215.3781\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0502 - val_loss: 213.4046\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0467 - val_loss: 211.4428\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0433 - val_loss: 209.4915\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: LearningRateScheduler reducing learning rate to tf.Tensor(5.4975597e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.0399 - val_loss: 207.5495\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0365 - val_loss: 205.6000\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0337 - val_loss: 203.6607\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0310 - val_loss: 201.7314\n",
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0283 - val_loss: 199.8121\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0255 - val_loss: 197.9028\n",
      "Epoch 285/2000\n",
      "\n",
      "Epoch 00285: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0228 - val_loss: 196.0037\n",
      "Epoch 286/2000\n",
      "\n",
      "Epoch 00286: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 4.0201 - val_loss: 194.1144\n",
      "Epoch 287/2000\n",
      "\n",
      "Epoch 00287: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 4.0174 - val_loss: 192.2375\n",
      "Epoch 288/2000\n",
      "\n",
      "Epoch 00288: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0146 - val_loss: 190.3791\n",
      "Epoch 289/2000\n",
      "\n",
      "Epoch 00289: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0119 - val_loss: 188.5459\n",
      "Epoch 290/2000\n",
      "\n",
      "Epoch 00290: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0092 - val_loss: 186.7265\n",
      "Epoch 291/2000\n",
      "\n",
      "Epoch 00291: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.0065 - val_loss: 184.9170\n",
      "Epoch 292/2000\n",
      "\n",
      "Epoch 00292: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 4.0038 - val_loss: 183.1176\n",
      "Epoch 293/2000\n",
      "\n",
      "Epoch 00293: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 4.0011 - val_loss: 181.3283\n",
      "Epoch 294/2000\n",
      "\n",
      "Epoch 00294: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9984 - val_loss: 179.5490\n",
      "Epoch 295/2000\n",
      "\n",
      "Epoch 00295: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9957 - val_loss: 177.7798\n",
      "Epoch 296/2000\n",
      "\n",
      "Epoch 00296: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9930 - val_loss: 176.0213\n",
      "Epoch 297/2000\n",
      "\n",
      "Epoch 00297: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9903 - val_loss: 174.2805\n",
      "Epoch 298/2000\n",
      "\n",
      "Epoch 00298: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9876 - val_loss: 172.5492\n",
      "Epoch 299/2000\n",
      "\n",
      "Epoch 00299: LearningRateScheduler reducing learning rate to tf.Tensor(4.398047e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9849 - val_loss: 170.8280\n",
      "Epoch 300/2000\n",
      "\n",
      "Epoch 00300: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9822 - val_loss: 169.1029\n",
      "Epoch 301/2000\n",
      "\n",
      "Epoch 00301: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9801 - val_loss: 167.3882\n",
      "Epoch 302/2000\n",
      "\n",
      "Epoch 00302: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9779 - val_loss: 165.6839\n",
      "Epoch 303/2000\n",
      "\n",
      "Epoch 00303: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9758 - val_loss: 163.9902\n",
      "Epoch 304/2000\n",
      "\n",
      "Epoch 00304: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9736 - val_loss: 162.3068\n",
      "Epoch 305/2000\n",
      "\n",
      "Epoch 00305: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9715 - val_loss: 160.6341\n",
      "Epoch 306/2000\n",
      "\n",
      "Epoch 00306: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9694 - val_loss: 158.9718\n",
      "Epoch 307/2000\n",
      "\n",
      "Epoch 00307: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9672 - val_loss: 157.3201\n",
      "Epoch 308/2000\n",
      "\n",
      "Epoch 00308: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9651 - val_loss: 155.6791\n",
      "Epoch 309/2000\n",
      "\n",
      "Epoch 00309: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9630 - val_loss: 154.0487\n",
      "Epoch 310/2000\n",
      "\n",
      "Epoch 00310: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9608 - val_loss: 152.4289\n",
      "Epoch 311/2000\n",
      "\n",
      "Epoch 00311: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9587 - val_loss: 150.8210\n",
      "Epoch 312/2000\n",
      "\n",
      "Epoch 00312: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9566 - val_loss: 149.2253\n",
      "Epoch 313/2000\n",
      "\n",
      "Epoch 00313: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9544 - val_loss: 147.6501\n",
      "Epoch 314/2000\n",
      "\n",
      "Epoch 00314: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9523 - val_loss: 146.1110\n",
      "Epoch 315/2000\n",
      "\n",
      "Epoch 00315: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9502 - val_loss: 144.6024\n",
      "Epoch 316/2000\n",
      "\n",
      "Epoch 00316: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9481 - val_loss: 143.1136\n",
      "Epoch 317/2000\n",
      "\n",
      "Epoch 00317: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9460 - val_loss: 141.6357\n",
      "Epoch 318/2000\n",
      "\n",
      "Epoch 00318: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9438 - val_loss: 140.1674\n",
      "Epoch 319/2000\n",
      "\n",
      "Epoch 00319: LearningRateScheduler reducing learning rate to tf.Tensor(3.518438e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9417 - val_loss: 138.7086\n",
      "Epoch 320/2000\n",
      "\n",
      "Epoch 00320: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.9396 - val_loss: 137.2486\n",
      "Epoch 321/2000\n",
      "\n",
      "Epoch 00321: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9379 - val_loss: 135.7989\n",
      "Epoch 322/2000\n",
      "\n",
      "Epoch 00322: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9362 - val_loss: 134.3590\n",
      "Epoch 323/2000\n",
      "\n",
      "Epoch 00323: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9345 - val_loss: 132.9288\n",
      "Epoch 324/2000\n",
      "\n",
      "Epoch 00324: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9328 - val_loss: 131.5143\n",
      "Epoch 325/2000\n",
      "\n",
      "Epoch 00325: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9312 - val_loss: 130.1157\n",
      "Epoch 326/2000\n",
      "\n",
      "Epoch 00326: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9295 - val_loss: 128.7275\n",
      "Epoch 327/2000\n",
      "\n",
      "Epoch 00327: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9278 - val_loss: 127.3495\n",
      "Epoch 328/2000\n",
      "\n",
      "Epoch 00328: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9261 - val_loss: 125.9817\n",
      "Epoch 329/2000\n",
      "\n",
      "Epoch 00329: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9244 - val_loss: 124.6236\n",
      "Epoch 330/2000\n",
      "\n",
      "Epoch 00330: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9227 - val_loss: 123.2753\n",
      "Epoch 331/2000\n",
      "\n",
      "Epoch 00331: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.9211 - val_loss: 121.9366\n",
      "Epoch 332/2000\n",
      "\n",
      "Epoch 00332: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.9194 - val_loss: 120.6075\n",
      "Epoch 333/2000\n",
      "\n",
      "Epoch 00333: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9177 - val_loss: 119.2882\n",
      "Epoch 334/2000\n",
      "\n",
      "Epoch 00334: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.9160 - val_loss: 117.9785\n",
      "Epoch 335/2000\n",
      "\n",
      "Epoch 00335: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9143 - val_loss: 116.6787\n",
      "Epoch 336/2000\n",
      "\n",
      "Epoch 00336: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9127 - val_loss: 115.3885\n",
      "Epoch 337/2000\n",
      "\n",
      "Epoch 00337: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9110 - val_loss: 114.1079\n",
      "Epoch 338/2000\n",
      "\n",
      "Epoch 00338: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9093 - val_loss: 112.8370\n",
      "Epoch 339/2000\n",
      "\n",
      "Epoch 00339: LearningRateScheduler reducing learning rate to tf.Tensor(2.8147506e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9076 - val_loss: 111.5759\n",
      "Epoch 340/2000\n",
      "\n",
      "Epoch 00340: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9060 - val_loss: 110.3156\n",
      "Epoch 341/2000\n",
      "\n",
      "Epoch 00341: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9046 - val_loss: 109.0654\n",
      "Epoch 342/2000\n",
      "\n",
      "Epoch 00342: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9033 - val_loss: 107.8249\n",
      "Epoch 343/2000\n",
      "\n",
      "Epoch 00343: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.9019 - val_loss: 106.5942\n",
      "Epoch 344/2000\n",
      "\n",
      "Epoch 00344: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.9006 - val_loss: 105.3762\n",
      "Epoch 345/2000\n",
      "\n",
      "Epoch 00345: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8993 - val_loss: 104.1753\n",
      "Epoch 346/2000\n",
      "\n",
      "Epoch 00346: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8979 - val_loss: 102.9874\n",
      "Epoch 347/2000\n",
      "\n",
      "Epoch 00347: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8966 - val_loss: 101.8169\n",
      "Epoch 348/2000\n",
      "\n",
      "Epoch 00348: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8953 - val_loss: 100.6700\n",
      "Epoch 349/2000\n",
      "\n",
      "Epoch 00349: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8939 - val_loss: 99.5321\n",
      "Epoch 350/2000\n",
      "\n",
      "Epoch 00350: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8926 - val_loss: 98.4034\n",
      "Epoch 351/2000\n",
      "\n",
      "Epoch 00351: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8913 - val_loss: 97.2837\n",
      "Epoch 352/2000\n",
      "\n",
      "Epoch 00352: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8899 - val_loss: 96.1785\n",
      "Epoch 353/2000\n",
      "\n",
      "Epoch 00353: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8886 - val_loss: 95.0897\n",
      "Epoch 354/2000\n",
      "\n",
      "Epoch 00354: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8873 - val_loss: 94.0113\n",
      "Epoch 355/2000\n",
      "\n",
      "Epoch 00355: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8860 - val_loss: 92.9417\n",
      "Epoch 356/2000\n",
      "\n",
      "Epoch 00356: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8846 - val_loss: 91.8810\n",
      "Epoch 357/2000\n",
      "\n",
      "Epoch 00357: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8833 - val_loss: 90.8290\n",
      "Epoch 358/2000\n",
      "\n",
      "Epoch 00358: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8820 - val_loss: 89.7868\n",
      "Epoch 359/2000\n",
      "\n",
      "Epoch 00359: LearningRateScheduler reducing learning rate to tf.Tensor(2.2518007e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8806 - val_loss: 88.7610\n",
      "Epoch 360/2000\n",
      "\n",
      "Epoch 00360: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8793 - val_loss: 87.7382\n",
      "Epoch 361/2000\n",
      "\n",
      "Epoch 00361: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8783 - val_loss: 86.7279\n",
      "Epoch 362/2000\n",
      "\n",
      "Epoch 00362: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8772 - val_loss: 85.7269\n",
      "Epoch 363/2000\n",
      "\n",
      "Epoch 00363: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8761 - val_loss: 84.7346\n",
      "Epoch 364/2000\n",
      "\n",
      "Epoch 00364: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8751 - val_loss: 83.7514\n",
      "Epoch 365/2000\n",
      "\n",
      "Epoch 00365: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8740 - val_loss: 82.7765\n",
      "Epoch 366/2000\n",
      "\n",
      "Epoch 00366: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8730 - val_loss: 81.8101\n",
      "Epoch 367/2000\n",
      "\n",
      "Epoch 00367: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8719 - val_loss: 80.8521\n",
      "Epoch 368/2000\n",
      "\n",
      "Epoch 00368: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8708 - val_loss: 79.9026\n",
      "Epoch 369/2000\n",
      "\n",
      "Epoch 00369: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8698 - val_loss: 78.9615\n",
      "Epoch 370/2000\n",
      "\n",
      "Epoch 00370: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8687 - val_loss: 78.0289\n",
      "Epoch 371/2000\n",
      "\n",
      "Epoch 00371: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8677 - val_loss: 77.1047\n",
      "Epoch 372/2000\n",
      "\n",
      "Epoch 00372: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8666 - val_loss: 76.1889\n",
      "Epoch 373/2000\n",
      "\n",
      "Epoch 00373: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8656 - val_loss: 75.2813\n",
      "Epoch 374/2000\n",
      "\n",
      "Epoch 00374: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8645 - val_loss: 74.3821\n",
      "Epoch 375/2000\n",
      "\n",
      "Epoch 00375: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8635 - val_loss: 73.4911\n",
      "Epoch 376/2000\n",
      "\n",
      "Epoch 00376: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8624 - val_loss: 72.6084\n",
      "Epoch 377/2000\n",
      "\n",
      "Epoch 00377: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8614 - val_loss: 71.7340\n",
      "Epoch 378/2000\n",
      "\n",
      "Epoch 00378: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8603 - val_loss: 70.8676\n",
      "Epoch 379/2000\n",
      "\n",
      "Epoch 00379: LearningRateScheduler reducing learning rate to tf.Tensor(1.8014402e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8592 - val_loss: 70.0094\n",
      "Epoch 380/2000\n",
      "\n",
      "Epoch 00380: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8582 - val_loss: 69.1546\n",
      "Epoch 381/2000\n",
      "\n",
      "Epoch 00381: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8574 - val_loss: 68.3083\n",
      "Epoch 382/2000\n",
      "\n",
      "Epoch 00382: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8565 - val_loss: 67.4703\n",
      "Epoch 383/2000\n",
      "\n",
      "Epoch 00383: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8557 - val_loss: 66.6403\n",
      "Epoch 384/2000\n",
      "\n",
      "Epoch 00384: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8548 - val_loss: 65.8185\n",
      "Epoch 385/2000\n",
      "\n",
      "Epoch 00385: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8540 - val_loss: 65.0059\n",
      "Epoch 386/2000\n",
      "\n",
      "Epoch 00386: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8532 - val_loss: 64.2070\n",
      "Epoch 387/2000\n",
      "\n",
      "Epoch 00387: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8523 - val_loss: 63.4163\n",
      "Epoch 388/2000\n",
      "\n",
      "Epoch 00388: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8515 - val_loss: 62.6360\n",
      "Epoch 389/2000\n",
      "\n",
      "Epoch 00389: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8506 - val_loss: 61.8650\n",
      "Epoch 390/2000\n",
      "\n",
      "Epoch 00390: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8498 - val_loss: 61.1061\n",
      "Epoch 391/2000\n",
      "\n",
      "Epoch 00391: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8490 - val_loss: 60.3566\n",
      "Epoch 392/2000\n",
      "\n",
      "Epoch 00392: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8481 - val_loss: 59.6178\n",
      "Epoch 393/2000\n",
      "\n",
      "Epoch 00393: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8473 - val_loss: 58.8865\n",
      "Epoch 394/2000\n",
      "\n",
      "Epoch 00394: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8464 - val_loss: 58.1623\n",
      "Epoch 395/2000\n",
      "\n",
      "Epoch 00395: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8456 - val_loss: 57.4456\n",
      "Epoch 396/2000\n",
      "\n",
      "Epoch 00396: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8448 - val_loss: 56.7390\n",
      "Epoch 397/2000\n",
      "\n",
      "Epoch 00397: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8439 - val_loss: 56.0400\n",
      "Epoch 398/2000\n",
      "\n",
      "Epoch 00398: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8431 - val_loss: 55.3480\n",
      "Epoch 399/2000\n",
      "\n",
      "Epoch 00399: LearningRateScheduler reducing learning rate to tf.Tensor(1.4411522e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8423 - val_loss: 54.6630\n",
      "Epoch 400/2000\n",
      "\n",
      "Epoch 00400: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8414 - val_loss: 53.9815\n",
      "Epoch 401/2000\n",
      "\n",
      "Epoch 00401: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8408 - val_loss: 53.3072\n",
      "Epoch 402/2000\n",
      "\n",
      "Epoch 00402: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8401 - val_loss: 52.6399\n",
      "Epoch 403/2000\n",
      "\n",
      "Epoch 00403: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8394 - val_loss: 51.9796\n",
      "Epoch 404/2000\n",
      "\n",
      "Epoch 00404: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8388 - val_loss: 51.3265\n",
      "Epoch 405/2000\n",
      "\n",
      "Epoch 00405: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8381 - val_loss: 50.6832\n",
      "Epoch 406/2000\n",
      "\n",
      "Epoch 00406: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8374 - val_loss: 50.0466\n",
      "Epoch 407/2000\n",
      "\n",
      "Epoch 00407: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8367 - val_loss: 49.4168\n",
      "Epoch 408/2000\n",
      "\n",
      "Epoch 00408: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8361 - val_loss: 48.7937\n",
      "Epoch 409/2000\n",
      "\n",
      "Epoch 00409: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8354 - val_loss: 48.1773\n",
      "Epoch 410/2000\n",
      "\n",
      "Epoch 00410: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8347 - val_loss: 47.5676\n",
      "Epoch 411/2000\n",
      "\n",
      "Epoch 00411: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8341 - val_loss: 46.9644\n",
      "Epoch 412/2000\n",
      "\n",
      "Epoch 00412: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8334 - val_loss: 46.3679\n",
      "Epoch 413/2000\n",
      "\n",
      "Epoch 00413: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8327 - val_loss: 45.7778\n",
      "Epoch 414/2000\n",
      "\n",
      "Epoch 00414: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8321 - val_loss: 45.1942\n",
      "Epoch 415/2000\n",
      "\n",
      "Epoch 00415: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8314 - val_loss: 44.6170\n",
      "Epoch 416/2000\n",
      "\n",
      "Epoch 00416: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8307 - val_loss: 44.0463\n",
      "Epoch 417/2000\n",
      "\n",
      "Epoch 00417: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8301 - val_loss: 43.4818\n",
      "Epoch 418/2000\n",
      "\n",
      "Epoch 00418: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8294 - val_loss: 42.9237\n",
      "Epoch 419/2000\n",
      "\n",
      "Epoch 00419: LearningRateScheduler reducing learning rate to tf.Tensor(1.1529219e-05, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8287 - val_loss: 42.3719\n",
      "Epoch 420/2000\n",
      "\n",
      "Epoch 00420: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.8281 - val_loss: 41.8237\n",
      "Epoch 421/2000\n",
      "\n",
      "Epoch 00421: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.8276 - val_loss: 41.2816\n",
      "Epoch 422/2000\n",
      "\n",
      "Epoch 00422: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8270 - val_loss: 40.7458\n",
      "Epoch 423/2000\n",
      "\n",
      "Epoch 00423: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8265 - val_loss: 40.2161\n",
      "Epoch 424/2000\n",
      "\n",
      "Epoch 00424: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8260 - val_loss: 39.6927\n",
      "Epoch 425/2000\n",
      "\n",
      "Epoch 00425: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8254 - val_loss: 39.1752\n",
      "Epoch 426/2000\n",
      "\n",
      "Epoch 00426: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8249 - val_loss: 38.6637\n",
      "Epoch 427/2000\n",
      "\n",
      "Epoch 00427: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8244 - val_loss: 38.1583\n",
      "Epoch 428/2000\n",
      "\n",
      "Epoch 00428: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8238 - val_loss: 37.6587\n",
      "Epoch 429/2000\n",
      "\n",
      "Epoch 00429: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8233 - val_loss: 37.1651\n",
      "Epoch 430/2000\n",
      "\n",
      "Epoch 00430: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8228 - val_loss: 36.6772\n",
      "Epoch 431/2000\n",
      "\n",
      "Epoch 00431: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8222 - val_loss: 36.1952\n",
      "Epoch 432/2000\n",
      "\n",
      "Epoch 00432: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8217 - val_loss: 35.7190\n",
      "Epoch 433/2000\n",
      "\n",
      "Epoch 00433: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8212 - val_loss: 35.2484\n",
      "Epoch 434/2000\n",
      "\n",
      "Epoch 00434: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8206 - val_loss: 34.7834\n",
      "Epoch 435/2000\n",
      "\n",
      "Epoch 00435: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8201 - val_loss: 34.3242\n",
      "Epoch 436/2000\n",
      "\n",
      "Epoch 00436: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8196 - val_loss: 33.8704\n",
      "Epoch 437/2000\n",
      "\n",
      "Epoch 00437: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8190 - val_loss: 33.4222\n",
      "Epoch 438/2000\n",
      "\n",
      "Epoch 00438: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 3.8185 - val_loss: 32.9795\n",
      "Epoch 439/2000\n",
      "\n",
      "Epoch 00439: LearningRateScheduler reducing learning rate to tf.Tensor(9.223375e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8180 - val_loss: 32.5422\n",
      "Epoch 440/2000\n",
      "\n",
      "Epoch 00440: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8175 - val_loss: 32.1083\n",
      "Epoch 441/2000\n",
      "\n",
      "Epoch 00441: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8170 - val_loss: 31.6799\n",
      "Epoch 442/2000\n",
      "\n",
      "Epoch 00442: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8166 - val_loss: 31.2567\n",
      "Epoch 443/2000\n",
      "\n",
      "Epoch 00443: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8162 - val_loss: 30.8388\n",
      "Epoch 444/2000\n",
      "\n",
      "Epoch 00444: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8158 - val_loss: 30.4263\n",
      "Epoch 445/2000\n",
      "\n",
      "Epoch 00445: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8153 - val_loss: 30.0189\n",
      "Epoch 446/2000\n",
      "\n",
      "Epoch 00446: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8149 - val_loss: 29.6175\n",
      "Epoch 447/2000\n",
      "\n",
      "Epoch 00447: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8145 - val_loss: 29.2222\n",
      "Epoch 448/2000\n",
      "\n",
      "Epoch 00448: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8141 - val_loss: 28.8319\n",
      "Epoch 449/2000\n",
      "\n",
      "Epoch 00449: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8136 - val_loss: 28.4467\n",
      "Epoch 450/2000\n",
      "\n",
      "Epoch 00450: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.8132 - val_loss: 28.0696\n",
      "Epoch 451/2000\n",
      "\n",
      "Epoch 00451: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8128 - val_loss: 27.6986\n",
      "Epoch 452/2000\n",
      "\n",
      "Epoch 00452: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8124 - val_loss: 27.3331\n",
      "Epoch 453/2000\n",
      "\n",
      "Epoch 00453: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.8119 - val_loss: 26.9722\n",
      "Epoch 454/2000\n",
      "\n",
      "Epoch 00454: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8115 - val_loss: 26.6160\n",
      "Epoch 455/2000\n",
      "\n",
      "Epoch 00455: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8111 - val_loss: 26.2650\n",
      "Epoch 456/2000\n",
      "\n",
      "Epoch 00456: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8107 - val_loss: 25.9197\n",
      "Epoch 457/2000\n",
      "\n",
      "Epoch 00457: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8103 - val_loss: 25.5788\n",
      "Epoch 458/2000\n",
      "\n",
      "Epoch 00458: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8098 - val_loss: 25.2439\n",
      "Epoch 459/2000\n",
      "\n",
      "Epoch 00459: LearningRateScheduler reducing learning rate to tf.Tensor(7.3787005e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8094 - val_loss: 24.9144\n",
      "Epoch 460/2000\n",
      "\n",
      "Epoch 00460: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8090 - val_loss: 24.5885\n",
      "Epoch 461/2000\n",
      "\n",
      "Epoch 00461: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.8086 - val_loss: 24.2669\n",
      "Epoch 462/2000\n",
      "\n",
      "Epoch 00462: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8083 - val_loss: 23.9495\n",
      "Epoch 463/2000\n",
      "\n",
      "Epoch 00463: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8080 - val_loss: 23.6363\n",
      "Epoch 464/2000\n",
      "\n",
      "Epoch 00464: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8076 - val_loss: 23.3272\n",
      "Epoch 465/2000\n",
      "\n",
      "Epoch 00465: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8073 - val_loss: 23.0222\n",
      "Epoch 466/2000\n",
      "\n",
      "Epoch 00466: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8070 - val_loss: 22.7213\n",
      "Epoch 467/2000\n",
      "\n",
      "Epoch 00467: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.8066 - val_loss: 22.4244\n",
      "Epoch 468/2000\n",
      "\n",
      "Epoch 00468: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.8063 - val_loss: 22.1314\n",
      "Epoch 469/2000\n",
      "\n",
      "Epoch 00469: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8059 - val_loss: 21.8424\n",
      "Epoch 470/2000\n",
      "\n",
      "Epoch 00470: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8056 - val_loss: 21.5571\n",
      "Epoch 471/2000\n",
      "\n",
      "Epoch 00471: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8053 - val_loss: 21.2758\n",
      "Epoch 472/2000\n",
      "\n",
      "Epoch 00472: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8049 - val_loss: 20.9983\n",
      "Epoch 473/2000\n",
      "\n",
      "Epoch 00473: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8046 - val_loss: 20.7245\n",
      "Epoch 474/2000\n",
      "\n",
      "Epoch 00474: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8042 - val_loss: 20.4544\n",
      "Epoch 475/2000\n",
      "\n",
      "Epoch 00475: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8039 - val_loss: 20.1880\n",
      "Epoch 476/2000\n",
      "\n",
      "Epoch 00476: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8036 - val_loss: 19.9253\n",
      "Epoch 477/2000\n",
      "\n",
      "Epoch 00477: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8032 - val_loss: 19.6662\n",
      "Epoch 478/2000\n",
      "\n",
      "Epoch 00478: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8029 - val_loss: 19.4106\n",
      "Epoch 479/2000\n",
      "\n",
      "Epoch 00479: LearningRateScheduler reducing learning rate to tf.Tensor(5.9029608e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8026 - val_loss: 19.1599\n",
      "Epoch 480/2000\n",
      "\n",
      "Epoch 00480: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.8022 - val_loss: 18.9117\n",
      "Epoch 481/2000\n",
      "\n",
      "Epoch 00481: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8020 - val_loss: 18.6669\n",
      "Epoch 482/2000\n",
      "\n",
      "Epoch 00482: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8017 - val_loss: 18.4257\n",
      "Epoch 483/2000\n",
      "\n",
      "Epoch 00483: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.8014 - val_loss: 18.1878\n",
      "Epoch 484/2000\n",
      "\n",
      "Epoch 00484: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8011 - val_loss: 17.9532\n",
      "Epoch 485/2000\n",
      "\n",
      "Epoch 00485: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8009 - val_loss: 17.7219\n",
      "Epoch 486/2000\n",
      "\n",
      "Epoch 00486: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.8006 - val_loss: 17.4940\n",
      "Epoch 487/2000\n",
      "\n",
      "Epoch 00487: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.8003 - val_loss: 17.2692\n",
      "Epoch 488/2000\n",
      "\n",
      "Epoch 00488: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.8001 - val_loss: 17.0477\n",
      "Epoch 489/2000\n",
      "\n",
      "Epoch 00489: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7998 - val_loss: 16.8292\n",
      "Epoch 490/2000\n",
      "\n",
      "Epoch 00490: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7995 - val_loss: 16.6139\n",
      "Epoch 491/2000\n",
      "\n",
      "Epoch 00491: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7993 - val_loss: 16.4016\n",
      "Epoch 492/2000\n",
      "\n",
      "Epoch 00492: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7990 - val_loss: 16.1924\n",
      "Epoch 493/2000\n",
      "\n",
      "Epoch 00493: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7987 - val_loss: 15.9862\n",
      "Epoch 494/2000\n",
      "\n",
      "Epoch 00494: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7984 - val_loss: 15.7829\n",
      "Epoch 495/2000\n",
      "\n",
      "Epoch 00495: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7982 - val_loss: 15.5826\n",
      "Epoch 496/2000\n",
      "\n",
      "Epoch 00496: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7979 - val_loss: 15.3852\n",
      "Epoch 497/2000\n",
      "\n",
      "Epoch 00497: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7976 - val_loss: 15.1906\n",
      "Epoch 498/2000\n",
      "\n",
      "Epoch 00498: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7974 - val_loss: 14.9988\n",
      "Epoch 499/2000\n",
      "\n",
      "Epoch 00499: LearningRateScheduler reducing learning rate to tf.Tensor(4.7223693e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7971 - val_loss: 14.8099\n",
      "Epoch 500/2000\n",
      "\n",
      "Epoch 00500: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7968 - val_loss: 14.6231\n",
      "Epoch 501/2000\n",
      "\n",
      "Epoch 00501: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7966 - val_loss: 14.4389\n",
      "Epoch 502/2000\n",
      "\n",
      "Epoch 00502: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7964 - val_loss: 14.2575\n",
      "Epoch 503/2000\n",
      "\n",
      "Epoch 00503: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7962 - val_loss: 14.0788\n",
      "Epoch 504/2000\n",
      "\n",
      "Epoch 00504: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7960 - val_loss: 13.9027\n",
      "Epoch 505/2000\n",
      "\n",
      "Epoch 00505: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7958 - val_loss: 13.7293\n",
      "Epoch 506/2000\n",
      "\n",
      "Epoch 00506: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7955 - val_loss: 13.5584\n",
      "Epoch 507/2000\n",
      "\n",
      "Epoch 00507: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7953 - val_loss: 13.3901\n",
      "Epoch 508/2000\n",
      "\n",
      "Epoch 00508: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7951 - val_loss: 13.2242\n",
      "Epoch 509/2000\n",
      "\n",
      "Epoch 00509: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7949 - val_loss: 13.0609\n",
      "Epoch 510/2000\n",
      "\n",
      "Epoch 00510: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7947 - val_loss: 12.9000\n",
      "Epoch 511/2000\n",
      "\n",
      "Epoch 00511: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7945 - val_loss: 12.7414\n",
      "Epoch 512/2000\n",
      "\n",
      "Epoch 00512: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7942 - val_loss: 12.5854\n",
      "Epoch 513/2000\n",
      "\n",
      "Epoch 00513: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7940 - val_loss: 12.4316\n",
      "Epoch 514/2000\n",
      "\n",
      "Epoch 00514: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7938 - val_loss: 12.2801\n",
      "Epoch 515/2000\n",
      "\n",
      "Epoch 00515: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7936 - val_loss: 12.1309\n",
      "Epoch 516/2000\n",
      "\n",
      "Epoch 00516: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7934 - val_loss: 11.9840\n",
      "Epoch 517/2000\n",
      "\n",
      "Epoch 00517: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7932 - val_loss: 11.8393\n",
      "Epoch 518/2000\n",
      "\n",
      "Epoch 00518: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7930 - val_loss: 11.6968\n",
      "Epoch 519/2000\n",
      "\n",
      "Epoch 00519: LearningRateScheduler reducing learning rate to tf.Tensor(3.7778952e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7927 - val_loss: 11.5565\n",
      "Epoch 520/2000\n",
      "\n",
      "Epoch 00520: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7925 - val_loss: 11.4179\n",
      "Epoch 521/2000\n",
      "\n",
      "Epoch 00521: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7924 - val_loss: 11.2815\n",
      "Epoch 522/2000\n",
      "\n",
      "Epoch 00522: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7922 - val_loss: 11.1471\n",
      "Epoch 523/2000\n",
      "\n",
      "Epoch 00523: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7920 - val_loss: 11.0148\n",
      "Epoch 524/2000\n",
      "\n",
      "Epoch 00524: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7918 - val_loss: 10.8845\n",
      "Epoch 525/2000\n",
      "\n",
      "Epoch 00525: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7917 - val_loss: 10.7563\n",
      "Epoch 526/2000\n",
      "\n",
      "Epoch 00526: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7915 - val_loss: 10.6300\n",
      "Epoch 527/2000\n",
      "\n",
      "Epoch 00527: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7913 - val_loss: 10.5057\n",
      "Epoch 528/2000\n",
      "\n",
      "Epoch 00528: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7911 - val_loss: 10.3834\n",
      "Epoch 529/2000\n",
      "\n",
      "Epoch 00529: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7910 - val_loss: 10.2629\n",
      "Epoch 530/2000\n",
      "\n",
      "Epoch 00530: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7908 - val_loss: 10.1443\n",
      "Epoch 531/2000\n",
      "\n",
      "Epoch 00531: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7906 - val_loss: 10.0276\n",
      "Epoch 532/2000\n",
      "\n",
      "Epoch 00532: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7905 - val_loss: 9.9127\n",
      "Epoch 533/2000\n",
      "\n",
      "Epoch 00533: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7903 - val_loss: 9.7997\n",
      "Epoch 534/2000\n",
      "\n",
      "Epoch 00534: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7901 - val_loss: 9.6883\n",
      "Epoch 535/2000\n",
      "\n",
      "Epoch 00535: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7899 - val_loss: 9.5788\n",
      "Epoch 536/2000\n",
      "\n",
      "Epoch 00536: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7898 - val_loss: 9.4710\n",
      "Epoch 537/2000\n",
      "\n",
      "Epoch 00537: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7896 - val_loss: 9.3649\n",
      "Epoch 538/2000\n",
      "\n",
      "Epoch 00538: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7894 - val_loss: 9.2605\n",
      "Epoch 539/2000\n",
      "\n",
      "Epoch 00539: LearningRateScheduler reducing learning rate to tf.Tensor(3.0223164e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7893 - val_loss: 9.1577\n",
      "Epoch 540/2000\n",
      "\n",
      "Epoch 00540: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7891 - val_loss: 9.0563\n",
      "Epoch 541/2000\n",
      "\n",
      "Epoch 00541: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7890 - val_loss: 8.9565\n",
      "Epoch 542/2000\n",
      "\n",
      "Epoch 00542: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7888 - val_loss: 8.8582\n",
      "Epoch 543/2000\n",
      "\n",
      "Epoch 00543: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7887 - val_loss: 8.7616\n",
      "Epoch 544/2000\n",
      "\n",
      "Epoch 00544: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7885 - val_loss: 8.6666\n",
      "Epoch 545/2000\n",
      "\n",
      "Epoch 00545: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7884 - val_loss: 8.5730\n",
      "Epoch 546/2000\n",
      "\n",
      "Epoch 00546: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7883 - val_loss: 8.4810\n",
      "Epoch 547/2000\n",
      "\n",
      "Epoch 00547: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7881 - val_loss: 8.3904\n",
      "Epoch 548/2000\n",
      "\n",
      "Epoch 00548: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7880 - val_loss: 8.3018\n",
      "Epoch 549/2000\n",
      "\n",
      "Epoch 00549: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7878 - val_loss: 8.2146\n",
      "Epoch 550/2000\n",
      "\n",
      "Epoch 00550: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7877 - val_loss: 8.1289\n",
      "Epoch 551/2000\n",
      "\n",
      "Epoch 00551: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7876 - val_loss: 8.0445\n",
      "Epoch 552/2000\n",
      "\n",
      "Epoch 00552: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7874 - val_loss: 7.9615\n",
      "Epoch 553/2000\n",
      "\n",
      "Epoch 00553: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7873 - val_loss: 7.8800\n",
      "Epoch 554/2000\n",
      "\n",
      "Epoch 00554: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7872 - val_loss: 7.8001\n",
      "Epoch 555/2000\n",
      "\n",
      "Epoch 00555: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7870 - val_loss: 7.7219\n",
      "Epoch 556/2000\n",
      "\n",
      "Epoch 00556: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7869 - val_loss: 7.6450\n",
      "Epoch 557/2000\n",
      "\n",
      "Epoch 00557: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7867 - val_loss: 7.5694\n",
      "Epoch 558/2000\n",
      "\n",
      "Epoch 00558: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7866 - val_loss: 7.4949\n",
      "Epoch 559/2000\n",
      "\n",
      "Epoch 00559: LearningRateScheduler reducing learning rate to tf.Tensor(2.417852e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7865 - val_loss: 7.4217\n",
      "Epoch 560/2000\n",
      "\n",
      "Epoch 00560: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7863 - val_loss: 7.3495\n",
      "Epoch 561/2000\n",
      "\n",
      "Epoch 00561: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7862 - val_loss: 7.2789\n",
      "Epoch 562/2000\n",
      "\n",
      "Epoch 00562: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7861 - val_loss: 7.2094\n",
      "Epoch 563/2000\n",
      "\n",
      "Epoch 00563: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7860 - val_loss: 7.1416\n",
      "Epoch 564/2000\n",
      "\n",
      "Epoch 00564: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7859 - val_loss: 7.0752\n",
      "Epoch 565/2000\n",
      "\n",
      "Epoch 00565: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7858 - val_loss: 7.0103\n",
      "Epoch 566/2000\n",
      "\n",
      "Epoch 00566: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7857 - val_loss: 6.9469\n",
      "Epoch 567/2000\n",
      "\n",
      "Epoch 00567: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7856 - val_loss: 6.8847\n",
      "Epoch 568/2000\n",
      "\n",
      "Epoch 00568: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7855 - val_loss: 6.8236\n",
      "Epoch 569/2000\n",
      "\n",
      "Epoch 00569: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7853 - val_loss: 6.7635\n",
      "Epoch 570/2000\n",
      "\n",
      "Epoch 00570: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7852 - val_loss: 6.7044\n",
      "Epoch 571/2000\n",
      "\n",
      "Epoch 00571: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7851 - val_loss: 6.6462\n",
      "Epoch 572/2000\n",
      "\n",
      "Epoch 00572: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7850 - val_loss: 6.5891\n",
      "Epoch 573/2000\n",
      "\n",
      "Epoch 00573: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7849 - val_loss: 6.5329\n",
      "Epoch 574/2000\n",
      "\n",
      "Epoch 00574: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7848 - val_loss: 6.4779\n",
      "Epoch 575/2000\n",
      "\n",
      "Epoch 00575: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7847 - val_loss: 6.4239\n",
      "Epoch 576/2000\n",
      "\n",
      "Epoch 00576: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7846 - val_loss: 6.3708\n",
      "Epoch 577/2000\n",
      "\n",
      "Epoch 00577: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7845 - val_loss: 6.3185\n",
      "Epoch 578/2000\n",
      "\n",
      "Epoch 00578: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7844 - val_loss: 6.2673\n",
      "Epoch 579/2000\n",
      "\n",
      "Epoch 00579: LearningRateScheduler reducing learning rate to tf.Tensor(1.934282e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7843 - val_loss: 6.2170\n",
      "Epoch 580/2000\n",
      "\n",
      "Epoch 00580: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7841 - val_loss: 6.1675\n",
      "Epoch 581/2000\n",
      "\n",
      "Epoch 00581: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7841 - val_loss: 6.1187\n",
      "Epoch 582/2000\n",
      "\n",
      "Epoch 00582: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7840 - val_loss: 6.0708\n",
      "Epoch 583/2000\n",
      "\n",
      "Epoch 00583: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7839 - val_loss: 6.0237\n",
      "Epoch 584/2000\n",
      "\n",
      "Epoch 00584: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7838 - val_loss: 5.9775\n",
      "Epoch 585/2000\n",
      "\n",
      "Epoch 00585: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7837 - val_loss: 5.9323\n",
      "Epoch 586/2000\n",
      "\n",
      "Epoch 00586: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7836 - val_loss: 5.8878\n",
      "Epoch 587/2000\n",
      "\n",
      "Epoch 00587: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7835 - val_loss: 5.8440\n",
      "Epoch 588/2000\n",
      "\n",
      "Epoch 00588: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7834 - val_loss: 5.8011\n",
      "Epoch 589/2000\n",
      "\n",
      "Epoch 00589: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7833 - val_loss: 5.7588\n",
      "Epoch 590/2000\n",
      "\n",
      "Epoch 00590: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7833 - val_loss: 5.7173\n",
      "Epoch 591/2000\n",
      "\n",
      "Epoch 00591: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7832 - val_loss: 5.6764\n",
      "Epoch 592/2000\n",
      "\n",
      "Epoch 00592: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7831 - val_loss: 5.6363\n",
      "Epoch 593/2000\n",
      "\n",
      "Epoch 00593: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7830 - val_loss: 5.5968\n",
      "Epoch 594/2000\n",
      "\n",
      "Epoch 00594: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7829 - val_loss: 5.5580\n",
      "Epoch 595/2000\n",
      "\n",
      "Epoch 00595: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7828 - val_loss: 5.5198\n",
      "Epoch 596/2000\n",
      "\n",
      "Epoch 00596: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7827 - val_loss: 5.4823\n",
      "Epoch 597/2000\n",
      "\n",
      "Epoch 00597: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7826 - val_loss: 5.4455\n",
      "Epoch 598/2000\n",
      "\n",
      "Epoch 00598: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7826 - val_loss: 5.4094\n",
      "Epoch 599/2000\n",
      "\n",
      "Epoch 00599: LearningRateScheduler reducing learning rate to tf.Tensor(1.5474255e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7825 - val_loss: 5.3740\n",
      "Epoch 600/2000\n",
      "\n",
      "Epoch 00600: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7824 - val_loss: 5.3391\n",
      "Epoch 601/2000\n",
      "\n",
      "Epoch 00601: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7823 - val_loss: 5.3048\n",
      "Epoch 602/2000\n",
      "\n",
      "Epoch 00602: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7822 - val_loss: 5.2710\n",
      "Epoch 603/2000\n",
      "\n",
      "Epoch 00603: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7822 - val_loss: 5.2379\n",
      "Epoch 604/2000\n",
      "\n",
      "Epoch 00604: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7821 - val_loss: 5.2053\n",
      "Epoch 605/2000\n",
      "\n",
      "Epoch 00605: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7820 - val_loss: 5.1733\n",
      "Epoch 606/2000\n",
      "\n",
      "Epoch 00606: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7820 - val_loss: 5.1419\n",
      "Epoch 607/2000\n",
      "\n",
      "Epoch 00607: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7819 - val_loss: 5.1109\n",
      "Epoch 608/2000\n",
      "\n",
      "Epoch 00608: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7818 - val_loss: 5.0806\n",
      "Epoch 609/2000\n",
      "\n",
      "Epoch 00609: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7817 - val_loss: 5.0507\n",
      "Epoch 610/2000\n",
      "\n",
      "Epoch 00610: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7817 - val_loss: 5.0213\n",
      "Epoch 611/2000\n",
      "\n",
      "Epoch 00611: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7816 - val_loss: 4.9925\n",
      "Epoch 612/2000\n",
      "\n",
      "Epoch 00612: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7815 - val_loss: 4.9642\n",
      "Epoch 613/2000\n",
      "\n",
      "Epoch 00613: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7815 - val_loss: 4.9363\n",
      "Epoch 614/2000\n",
      "\n",
      "Epoch 00614: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7814 - val_loss: 4.9090\n",
      "Epoch 615/2000\n",
      "\n",
      "Epoch 00615: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7813 - val_loss: 4.8821\n",
      "Epoch 616/2000\n",
      "\n",
      "Epoch 00616: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7813 - val_loss: 4.8556\n",
      "Epoch 617/2000\n",
      "\n",
      "Epoch 00617: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7812 - val_loss: 4.8297\n",
      "Epoch 618/2000\n",
      "\n",
      "Epoch 00618: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7811 - val_loss: 4.8042\n",
      "Epoch 619/2000\n",
      "\n",
      "Epoch 00619: LearningRateScheduler reducing learning rate to tf.Tensor(1.2379404e-06, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7810 - val_loss: 4.7791\n",
      "Epoch 620/2000\n",
      "\n",
      "Epoch 00620: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7810 - val_loss: 4.7544\n",
      "Epoch 621/2000\n",
      "\n",
      "Epoch 00621: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7809 - val_loss: 4.7302\n",
      "Epoch 622/2000\n",
      "\n",
      "Epoch 00622: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7809 - val_loss: 4.7064\n",
      "Epoch 623/2000\n",
      "\n",
      "Epoch 00623: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7808 - val_loss: 4.6830\n",
      "Epoch 624/2000\n",
      "\n",
      "Epoch 00624: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7808 - val_loss: 4.6600\n",
      "Epoch 625/2000\n",
      "\n",
      "Epoch 00625: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7807 - val_loss: 4.6374\n",
      "Epoch 626/2000\n",
      "\n",
      "Epoch 00626: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7806 - val_loss: 4.6152\n",
      "Epoch 627/2000\n",
      "\n",
      "Epoch 00627: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7806 - val_loss: 4.5934\n",
      "Epoch 628/2000\n",
      "\n",
      "Epoch 00628: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7805 - val_loss: 4.5720\n",
      "Epoch 629/2000\n",
      "\n",
      "Epoch 00629: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7805 - val_loss: 4.5509\n",
      "Epoch 630/2000\n",
      "\n",
      "Epoch 00630: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7804 - val_loss: 4.5303\n",
      "Epoch 631/2000\n",
      "\n",
      "Epoch 00631: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7804 - val_loss: 4.5099\n",
      "Epoch 632/2000\n",
      "\n",
      "Epoch 00632: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7803 - val_loss: 4.4900\n",
      "Epoch 633/2000\n",
      "\n",
      "Epoch 00633: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7802 - val_loss: 4.4704\n",
      "Epoch 634/2000\n",
      "\n",
      "Epoch 00634: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7802 - val_loss: 4.4512\n",
      "Epoch 635/2000\n",
      "\n",
      "Epoch 00635: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7801 - val_loss: 4.4323\n",
      "Epoch 636/2000\n",
      "\n",
      "Epoch 00636: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7801 - val_loss: 4.4137\n",
      "Epoch 637/2000\n",
      "\n",
      "Epoch 00637: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7800 - val_loss: 4.3955\n",
      "Epoch 638/2000\n",
      "\n",
      "Epoch 00638: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7800 - val_loss: 4.3776\n",
      "Epoch 639/2000\n",
      "\n",
      "Epoch 00639: LearningRateScheduler reducing learning rate to tf.Tensor(9.903524e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7799 - val_loss: 4.3600\n",
      "Epoch 640/2000\n",
      "\n",
      "Epoch 00640: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7799 - val_loss: 4.3427\n",
      "Epoch 641/2000\n",
      "\n",
      "Epoch 00641: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7798 - val_loss: 4.3257\n",
      "Epoch 642/2000\n",
      "\n",
      "Epoch 00642: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7798 - val_loss: 4.3090\n",
      "Epoch 643/2000\n",
      "\n",
      "Epoch 00643: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7797 - val_loss: 4.2926\n",
      "Epoch 644/2000\n",
      "\n",
      "Epoch 00644: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7797 - val_loss: 4.2765\n",
      "Epoch 645/2000\n",
      "\n",
      "Epoch 00645: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7796 - val_loss: 4.2607\n",
      "Epoch 646/2000\n",
      "\n",
      "Epoch 00646: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7796 - val_loss: 4.2452\n",
      "Epoch 647/2000\n",
      "\n",
      "Epoch 00647: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7795 - val_loss: 4.2299\n",
      "Epoch 648/2000\n",
      "\n",
      "Epoch 00648: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7795 - val_loss: 4.2150\n",
      "Epoch 649/2000\n",
      "\n",
      "Epoch 00649: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 3.7795 - val_loss: 4.2003\n",
      "Epoch 650/2000\n",
      "\n",
      "Epoch 00650: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7794 - val_loss: 4.1859\n",
      "Epoch 651/2000\n",
      "\n",
      "Epoch 00651: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7794 - val_loss: 4.1717\n",
      "Epoch 652/2000\n",
      "\n",
      "Epoch 00652: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7793 - val_loss: 4.1578\n",
      "Epoch 653/2000\n",
      "\n",
      "Epoch 00653: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7793 - val_loss: 4.1441\n",
      "Epoch 654/2000\n",
      "\n",
      "Epoch 00654: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7792 - val_loss: 4.1307\n",
      "Epoch 655/2000\n",
      "\n",
      "Epoch 00655: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7792 - val_loss: 4.1175\n",
      "Epoch 656/2000\n",
      "\n",
      "Epoch 00656: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7791 - val_loss: 4.1046\n",
      "Epoch 657/2000\n",
      "\n",
      "Epoch 00657: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7791 - val_loss: 4.0919\n",
      "Epoch 658/2000\n",
      "\n",
      "Epoch 00658: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7790 - val_loss: 4.0795\n",
      "Epoch 659/2000\n",
      "\n",
      "Epoch 00659: LearningRateScheduler reducing learning rate to tf.Tensor(7.922821e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7790 - val_loss: 4.0673\n",
      "Epoch 660/2000\n",
      "\n",
      "Epoch 00660: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7790 - val_loss: 4.0552\n",
      "Epoch 661/2000\n",
      "\n",
      "Epoch 00661: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7789 - val_loss: 4.0434\n",
      "Epoch 662/2000\n",
      "\n",
      "Epoch 00662: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7789 - val_loss: 4.0318\n",
      "Epoch 663/2000\n",
      "\n",
      "Epoch 00663: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7788 - val_loss: 4.0205\n",
      "Epoch 664/2000\n",
      "\n",
      "Epoch 00664: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7788 - val_loss: 4.0095\n",
      "Epoch 665/2000\n",
      "\n",
      "Epoch 00665: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7788 - val_loss: 3.9986\n",
      "Epoch 666/2000\n",
      "\n",
      "Epoch 00666: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7787 - val_loss: 3.9879\n",
      "Epoch 667/2000\n",
      "\n",
      "Epoch 00667: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7787 - val_loss: 3.9774\n",
      "Epoch 668/2000\n",
      "\n",
      "Epoch 00668: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7787 - val_loss: 3.9672\n",
      "Epoch 669/2000\n",
      "\n",
      "Epoch 00669: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7786 - val_loss: 3.9572\n",
      "Epoch 670/2000\n",
      "\n",
      "Epoch 00670: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7786 - val_loss: 3.9473\n",
      "Epoch 671/2000\n",
      "\n",
      "Epoch 00671: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7786 - val_loss: 3.9377\n",
      "Epoch 672/2000\n",
      "\n",
      "Epoch 00672: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7785 - val_loss: 3.9282\n",
      "Epoch 673/2000\n",
      "\n",
      "Epoch 00673: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7785 - val_loss: 3.9190\n",
      "Epoch 674/2000\n",
      "\n",
      "Epoch 00674: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7785 - val_loss: 3.9099\n",
      "Epoch 675/2000\n",
      "\n",
      "Epoch 00675: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7784 - val_loss: 3.9009\n",
      "Epoch 676/2000\n",
      "\n",
      "Epoch 00676: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7784 - val_loss: 3.8921\n",
      "Epoch 677/2000\n",
      "\n",
      "Epoch 00677: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7783 - val_loss: 3.8835\n",
      "Epoch 678/2000\n",
      "\n",
      "Epoch 00678: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7783 - val_loss: 3.8751\n",
      "Epoch 679/2000\n",
      "\n",
      "Epoch 00679: LearningRateScheduler reducing learning rate to tf.Tensor(6.3382566e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7783 - val_loss: 3.8668\n",
      "Epoch 680/2000\n",
      "\n",
      "Epoch 00680: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7782 - val_loss: 3.8586\n",
      "Epoch 681/2000\n",
      "\n",
      "Epoch 00681: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7782 - val_loss: 3.8507\n",
      "Epoch 682/2000\n",
      "\n",
      "Epoch 00682: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7782 - val_loss: 3.8428\n",
      "Epoch 683/2000\n",
      "\n",
      "Epoch 00683: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7782 - val_loss: 3.8351\n",
      "Epoch 684/2000\n",
      "\n",
      "Epoch 00684: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7781 - val_loss: 3.8276\n",
      "Epoch 685/2000\n",
      "\n",
      "Epoch 00685: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7781 - val_loss: 3.8202\n",
      "Epoch 686/2000\n",
      "\n",
      "Epoch 00686: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7781 - val_loss: 3.8129\n",
      "Epoch 687/2000\n",
      "\n",
      "Epoch 00687: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7780 - val_loss: 3.8058\n",
      "Epoch 688/2000\n",
      "\n",
      "Epoch 00688: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7780 - val_loss: 3.7988\n",
      "Epoch 689/2000\n",
      "\n",
      "Epoch 00689: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7780 - val_loss: 3.7919\n",
      "Epoch 690/2000\n",
      "\n",
      "Epoch 00690: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7780 - val_loss: 3.7852\n",
      "Epoch 691/2000\n",
      "\n",
      "Epoch 00691: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7779 - val_loss: 3.7786\n",
      "Epoch 692/2000\n",
      "\n",
      "Epoch 00692: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7779 - val_loss: 3.7721\n",
      "Epoch 693/2000\n",
      "\n",
      "Epoch 00693: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7779 - val_loss: 3.7657\n",
      "Epoch 694/2000\n",
      "\n",
      "Epoch 00694: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7778 - val_loss: 3.7595\n",
      "Epoch 695/2000\n",
      "\n",
      "Epoch 00695: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7778 - val_loss: 3.7534\n",
      "Epoch 696/2000\n",
      "\n",
      "Epoch 00696: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7778 - val_loss: 3.7474\n",
      "Epoch 697/2000\n",
      "\n",
      "Epoch 00697: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7778 - val_loss: 3.7415\n",
      "Epoch 698/2000\n",
      "\n",
      "Epoch 00698: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7777 - val_loss: 3.7358\n",
      "Epoch 699/2000\n",
      "\n",
      "Epoch 00699: LearningRateScheduler reducing learning rate to tf.Tensor(5.070606e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7777 - val_loss: 3.7301\n",
      "Epoch 700/2000\n",
      "\n",
      "Epoch 00700: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7777 - val_loss: 3.7246\n",
      "Epoch 701/2000\n",
      "\n",
      "Epoch 00701: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7776 - val_loss: 3.7191\n",
      "Epoch 702/2000\n",
      "\n",
      "Epoch 00702: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7776 - val_loss: 3.7138\n",
      "Epoch 703/2000\n",
      "\n",
      "Epoch 00703: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7776 - val_loss: 3.7085\n",
      "Epoch 704/2000\n",
      "\n",
      "Epoch 00704: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7776 - val_loss: 3.7034\n",
      "Epoch 705/2000\n",
      "\n",
      "Epoch 00705: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7776 - val_loss: 3.6984\n",
      "Epoch 706/2000\n",
      "\n",
      "Epoch 00706: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7775 - val_loss: 3.6934\n",
      "Epoch 707/2000\n",
      "\n",
      "Epoch 00707: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7775 - val_loss: 3.6886\n",
      "Epoch 708/2000\n",
      "\n",
      "Epoch 00708: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7775 - val_loss: 3.6839\n",
      "Epoch 709/2000\n",
      "\n",
      "Epoch 00709: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7775 - val_loss: 3.6792\n",
      "Epoch 710/2000\n",
      "\n",
      "Epoch 00710: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7774 - val_loss: 3.6746\n",
      "Epoch 711/2000\n",
      "\n",
      "Epoch 00711: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7774 - val_loss: 3.6702\n",
      "Epoch 712/2000\n",
      "\n",
      "Epoch 00712: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7774 - val_loss: 3.6658\n",
      "Epoch 713/2000\n",
      "\n",
      "Epoch 00713: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7774 - val_loss: 3.6615\n",
      "Epoch 714/2000\n",
      "\n",
      "Epoch 00714: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7774 - val_loss: 3.6573\n",
      "Epoch 715/2000\n",
      "\n",
      "Epoch 00715: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7773 - val_loss: 3.6532\n",
      "Epoch 716/2000\n",
      "\n",
      "Epoch 00716: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7773 - val_loss: 3.6491\n",
      "Epoch 717/2000\n",
      "\n",
      "Epoch 00717: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7773 - val_loss: 3.6452\n",
      "Epoch 718/2000\n",
      "\n",
      "Epoch 00718: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7773 - val_loss: 3.6413\n",
      "Epoch 719/2000\n",
      "\n",
      "Epoch 00719: LearningRateScheduler reducing learning rate to tf.Tensor(4.0564848e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7772 - val_loss: 3.6375\n",
      "Epoch 720/2000\n",
      "\n",
      "Epoch 00720: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7772 - val_loss: 3.6337\n",
      "Epoch 721/2000\n",
      "\n",
      "Epoch 00721: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7772 - val_loss: 3.6300\n",
      "Epoch 722/2000\n",
      "\n",
      "Epoch 00722: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7772 - val_loss: 3.6264\n",
      "Epoch 723/2000\n",
      "\n",
      "Epoch 00723: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7772 - val_loss: 3.6229\n",
      "Epoch 724/2000\n",
      "\n",
      "Epoch 00724: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7771 - val_loss: 3.6194\n",
      "Epoch 725/2000\n",
      "\n",
      "Epoch 00725: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7771 - val_loss: 3.6160\n",
      "Epoch 726/2000\n",
      "\n",
      "Epoch 00726: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7771 - val_loss: 3.6127\n",
      "Epoch 727/2000\n",
      "\n",
      "Epoch 00727: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7771 - val_loss: 3.6094\n",
      "Epoch 728/2000\n",
      "\n",
      "Epoch 00728: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7771 - val_loss: 3.6063\n",
      "Epoch 729/2000\n",
      "\n",
      "Epoch 00729: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7770 - val_loss: 3.6031\n",
      "Epoch 730/2000\n",
      "\n",
      "Epoch 00730: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7770 - val_loss: 3.6001\n",
      "Epoch 731/2000\n",
      "\n",
      "Epoch 00731: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7770 - val_loss: 3.5971\n",
      "Epoch 732/2000\n",
      "\n",
      "Epoch 00732: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7770 - val_loss: 3.5941\n",
      "Epoch 733/2000\n",
      "\n",
      "Epoch 00733: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7770 - val_loss: 3.5912\n",
      "Epoch 734/2000\n",
      "\n",
      "Epoch 00734: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7770 - val_loss: 3.5884\n",
      "Epoch 735/2000\n",
      "\n",
      "Epoch 00735: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7769 - val_loss: 3.5857\n",
      "Epoch 736/2000\n",
      "\n",
      "Epoch 00736: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7769 - val_loss: 3.5830\n",
      "Epoch 737/2000\n",
      "\n",
      "Epoch 00737: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7769 - val_loss: 3.5803\n",
      "Epoch 738/2000\n",
      "\n",
      "Epoch 00738: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7769 - val_loss: 3.5777\n",
      "Epoch 739/2000\n",
      "\n",
      "Epoch 00739: LearningRateScheduler reducing learning rate to tf.Tensor(3.2451865e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7769 - val_loss: 3.5752\n",
      "Epoch 740/2000\n",
      "\n",
      "Epoch 00740: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7768 - val_loss: 3.5727\n",
      "Epoch 741/2000\n",
      "\n",
      "Epoch 00741: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7768 - val_loss: 3.5702\n",
      "Epoch 742/2000\n",
      "\n",
      "Epoch 00742: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7768 - val_loss: 3.5679\n",
      "Epoch 743/2000\n",
      "\n",
      "Epoch 00743: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7768 - val_loss: 3.5655\n",
      "Epoch 744/2000\n",
      "\n",
      "Epoch 00744: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7768 - val_loss: 3.5632\n",
      "Epoch 745/2000\n",
      "\n",
      "Epoch 00745: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7768 - val_loss: 3.5610\n",
      "Epoch 746/2000\n",
      "\n",
      "Epoch 00746: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7768 - val_loss: 3.5588\n",
      "Epoch 747/2000\n",
      "\n",
      "Epoch 00747: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7767 - val_loss: 3.5567\n",
      "Epoch 748/2000\n",
      "\n",
      "Epoch 00748: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7767 - val_loss: 3.5546\n",
      "Epoch 749/2000\n",
      "\n",
      "Epoch 00749: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7767 - val_loss: 3.5525\n",
      "Epoch 750/2000\n",
      "\n",
      "Epoch 00750: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7767 - val_loss: 3.5505\n",
      "Epoch 751/2000\n",
      "\n",
      "Epoch 00751: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7767 - val_loss: 3.5485\n",
      "Epoch 752/2000\n",
      "\n",
      "Epoch 00752: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7767 - val_loss: 3.5466\n",
      "Epoch 753/2000\n",
      "\n",
      "Epoch 00753: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7766 - val_loss: 3.5447\n",
      "Epoch 754/2000\n",
      "\n",
      "Epoch 00754: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7766 - val_loss: 3.5429\n",
      "Epoch 755/2000\n",
      "\n",
      "Epoch 00755: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7766 - val_loss: 3.5410\n",
      "Epoch 756/2000\n",
      "\n",
      "Epoch 00756: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7766 - val_loss: 3.5393\n",
      "Epoch 757/2000\n",
      "\n",
      "Epoch 00757: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7766 - val_loss: 3.5375\n",
      "Epoch 758/2000\n",
      "\n",
      "Epoch 00758: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7766 - val_loss: 3.5358\n",
      "Epoch 759/2000\n",
      "\n",
      "Epoch 00759: LearningRateScheduler reducing learning rate to tf.Tensor(2.5961495e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7766 - val_loss: 3.5341\n",
      "Epoch 760/2000\n",
      "\n",
      "Epoch 00760: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7765 - val_loss: 3.5325\n",
      "Epoch 761/2000\n",
      "\n",
      "Epoch 00761: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7765 - val_loss: 3.5309\n",
      "Epoch 762/2000\n",
      "\n",
      "Epoch 00762: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7765 - val_loss: 3.5293\n",
      "Epoch 763/2000\n",
      "\n",
      "Epoch 00763: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7765 - val_loss: 3.5278\n",
      "Epoch 764/2000\n",
      "\n",
      "Epoch 00764: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7765 - val_loss: 3.5262\n",
      "Epoch 765/2000\n",
      "\n",
      "Epoch 00765: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7765 - val_loss: 3.5248\n",
      "Epoch 766/2000\n",
      "\n",
      "Epoch 00766: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7765 - val_loss: 3.5233\n",
      "Epoch 767/2000\n",
      "\n",
      "Epoch 00767: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7765 - val_loss: 3.5219\n",
      "Epoch 768/2000\n",
      "\n",
      "Epoch 00768: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7765 - val_loss: 3.5205\n",
      "Epoch 769/2000\n",
      "\n",
      "Epoch 00769: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7764 - val_loss: 3.5192\n",
      "Epoch 770/2000\n",
      "\n",
      "Epoch 00770: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7764 - val_loss: 3.5178\n",
      "Epoch 771/2000\n",
      "\n",
      "Epoch 00771: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7764 - val_loss: 3.5165\n",
      "Epoch 772/2000\n",
      "\n",
      "Epoch 00772: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7764 - val_loss: 3.5152\n",
      "Epoch 773/2000\n",
      "\n",
      "Epoch 00773: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7764 - val_loss: 3.5140\n",
      "Epoch 774/2000\n",
      "\n",
      "Epoch 00774: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7764 - val_loss: 3.5127\n",
      "Epoch 775/2000\n",
      "\n",
      "Epoch 00775: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7764 - val_loss: 3.5115\n",
      "Epoch 776/2000\n",
      "\n",
      "Epoch 00776: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7764 - val_loss: 3.5103\n",
      "Epoch 777/2000\n",
      "\n",
      "Epoch 00777: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7764 - val_loss: 3.5092\n",
      "Epoch 778/2000\n",
      "\n",
      "Epoch 00778: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7763 - val_loss: 3.5080\n",
      "Epoch 779/2000\n",
      "\n",
      "Epoch 00779: LearningRateScheduler reducing learning rate to tf.Tensor(2.0769194e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7763 - val_loss: 3.5069\n",
      "Epoch 780/2000\n",
      "\n",
      "Epoch 00780: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7763 - val_loss: 3.5059\n",
      "Epoch 781/2000\n",
      "\n",
      "Epoch 00781: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7763 - val_loss: 3.5048\n",
      "Epoch 782/2000\n",
      "\n",
      "Epoch 00782: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7763 - val_loss: 3.5037\n",
      "Epoch 783/2000\n",
      "\n",
      "Epoch 00783: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7763 - val_loss: 3.5027\n",
      "Epoch 784/2000\n",
      "\n",
      "Epoch 00784: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7763 - val_loss: 3.5017\n",
      "Epoch 785/2000\n",
      "\n",
      "Epoch 00785: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7763 - val_loss: 3.5008\n",
      "Epoch 786/2000\n",
      "\n",
      "Epoch 00786: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7763 - val_loss: 3.4998\n",
      "Epoch 787/2000\n",
      "\n",
      "Epoch 00787: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7763 - val_loss: 3.4989\n",
      "Epoch 788/2000\n",
      "\n",
      "Epoch 00788: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7762 - val_loss: 3.4980\n",
      "Epoch 789/2000\n",
      "\n",
      "Epoch 00789: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7762 - val_loss: 3.4971\n",
      "Epoch 790/2000\n",
      "\n",
      "Epoch 00790: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7762 - val_loss: 3.4962\n",
      "Epoch 791/2000\n",
      "\n",
      "Epoch 00791: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7762 - val_loss: 3.4953\n",
      "Epoch 792/2000\n",
      "\n",
      "Epoch 00792: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7762 - val_loss: 3.4945\n",
      "Epoch 793/2000\n",
      "\n",
      "Epoch 00793: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7762 - val_loss: 3.4937\n",
      "Epoch 794/2000\n",
      "\n",
      "Epoch 00794: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7762 - val_loss: 3.4929\n",
      "Epoch 795/2000\n",
      "\n",
      "Epoch 00795: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7762 - val_loss: 3.4921\n",
      "Epoch 796/2000\n",
      "\n",
      "Epoch 00796: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7762 - val_loss: 3.4914\n",
      "Epoch 797/2000\n",
      "\n",
      "Epoch 00797: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7762 - val_loss: 3.4906\n",
      "Epoch 798/2000\n",
      "\n",
      "Epoch 00798: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7762 - val_loss: 3.4899\n",
      "Epoch 799/2000\n",
      "\n",
      "Epoch 00799: LearningRateScheduler reducing learning rate to tf.Tensor(1.6615357e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7761 - val_loss: 3.4892\n",
      "Epoch 800/2000\n",
      "\n",
      "Epoch 00800: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7761 - val_loss: 3.4885\n",
      "Epoch 801/2000\n",
      "\n",
      "Epoch 00801: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7761 - val_loss: 3.4879\n",
      "Epoch 802/2000\n",
      "\n",
      "Epoch 00802: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7761 - val_loss: 3.4872\n",
      "Epoch 803/2000\n",
      "\n",
      "Epoch 00803: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7761 - val_loss: 3.4866\n",
      "Epoch 804/2000\n",
      "\n",
      "Epoch 00804: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7761 - val_loss: 3.4859\n",
      "Epoch 805/2000\n",
      "\n",
      "Epoch 00805: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7761 - val_loss: 3.4853\n",
      "Epoch 806/2000\n",
      "\n",
      "Epoch 00806: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7761 - val_loss: 3.4847\n",
      "Epoch 807/2000\n",
      "\n",
      "Epoch 00807: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7761 - val_loss: 3.4842\n",
      "Epoch 808/2000\n",
      "\n",
      "Epoch 00808: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7761 - val_loss: 3.4836\n",
      "Epoch 809/2000\n",
      "\n",
      "Epoch 00809: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7761 - val_loss: 3.4830\n",
      "Epoch 810/2000\n",
      "\n",
      "Epoch 00810: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7761 - val_loss: 3.4825\n",
      "Epoch 811/2000\n",
      "\n",
      "Epoch 00811: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7761 - val_loss: 3.4820\n",
      "Epoch 812/2000\n",
      "\n",
      "Epoch 00812: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7761 - val_loss: 3.4815\n",
      "Epoch 813/2000\n",
      "\n",
      "Epoch 00813: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7760 - val_loss: 3.4810\n",
      "Epoch 814/2000\n",
      "\n",
      "Epoch 00814: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7760 - val_loss: 3.4805\n",
      "Epoch 815/2000\n",
      "\n",
      "Epoch 00815: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7760 - val_loss: 3.4800\n",
      "Epoch 816/2000\n",
      "\n",
      "Epoch 00816: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7760 - val_loss: 3.4796\n",
      "Epoch 817/2000\n",
      "\n",
      "Epoch 00817: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7760 - val_loss: 3.4791\n",
      "Epoch 818/2000\n",
      "\n",
      "Epoch 00818: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7760 - val_loss: 3.4787\n",
      "Epoch 819/2000\n",
      "\n",
      "Epoch 00819: LearningRateScheduler reducing learning rate to tf.Tensor(1.3292288e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7760 - val_loss: 3.4782\n",
      "Epoch 820/2000\n",
      "\n",
      "Epoch 00820: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7760 - val_loss: 3.4778\n",
      "Epoch 821/2000\n",
      "\n",
      "Epoch 00821: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7760 - val_loss: 3.4774\n",
      "Epoch 822/2000\n",
      "\n",
      "Epoch 00822: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7760 - val_loss: 3.4770\n",
      "Epoch 823/2000\n",
      "\n",
      "Epoch 00823: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7760 - val_loss: 3.4766\n",
      "Epoch 824/2000\n",
      "\n",
      "Epoch 00824: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7760 - val_loss: 3.4763\n",
      "Epoch 825/2000\n",
      "\n",
      "Epoch 00825: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7760 - val_loss: 3.4759\n",
      "Epoch 826/2000\n",
      "\n",
      "Epoch 00826: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7760 - val_loss: 3.4755\n",
      "Epoch 827/2000\n",
      "\n",
      "Epoch 00827: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7760 - val_loss: 3.4752\n",
      "Epoch 828/2000\n",
      "\n",
      "Epoch 00828: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7759 - val_loss: 3.4749\n",
      "Epoch 829/2000\n",
      "\n",
      "Epoch 00829: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7759 - val_loss: 3.4745\n",
      "Epoch 830/2000\n",
      "\n",
      "Epoch 00830: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7759 - val_loss: 3.4742\n",
      "Epoch 831/2000\n",
      "\n",
      "Epoch 00831: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7759 - val_loss: 3.4739\n",
      "Epoch 832/2000\n",
      "\n",
      "Epoch 00832: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7759 - val_loss: 3.4736\n",
      "Epoch 833/2000\n",
      "\n",
      "Epoch 00833: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7759 - val_loss: 3.4733\n",
      "Epoch 834/2000\n",
      "\n",
      "Epoch 00834: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7759 - val_loss: 3.4730\n",
      "Epoch 835/2000\n",
      "\n",
      "Epoch 00835: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7759 - val_loss: 3.4727\n",
      "Epoch 836/2000\n",
      "\n",
      "Epoch 00836: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7759 - val_loss: 3.4725\n",
      "Epoch 837/2000\n",
      "\n",
      "Epoch 00837: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7759 - val_loss: 3.4722\n",
      "Epoch 838/2000\n",
      "\n",
      "Epoch 00838: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7759 - val_loss: 3.4720\n",
      "Epoch 839/2000\n",
      "\n",
      "Epoch 00839: LearningRateScheduler reducing learning rate to tf.Tensor(1.063383e-07, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7759 - val_loss: 3.4717\n",
      "Epoch 840/2000\n",
      "\n",
      "Epoch 00840: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7759 - val_loss: 3.4715\n",
      "Epoch 841/2000\n",
      "\n",
      "Epoch 00841: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7759 - val_loss: 3.4712\n",
      "Epoch 842/2000\n",
      "\n",
      "Epoch 00842: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7759 - val_loss: 3.4710\n",
      "Epoch 843/2000\n",
      "\n",
      "Epoch 00843: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7759 - val_loss: 3.4708\n",
      "Epoch 844/2000\n",
      "\n",
      "Epoch 00844: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7759 - val_loss: 3.4706\n",
      "Epoch 845/2000\n",
      "\n",
      "Epoch 00845: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7759 - val_loss: 3.4704\n",
      "Epoch 846/2000\n",
      "\n",
      "Epoch 00846: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4702\n",
      "Epoch 847/2000\n",
      "\n",
      "Epoch 00847: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4700\n",
      "Epoch 848/2000\n",
      "\n",
      "Epoch 00848: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4698\n",
      "Epoch 849/2000\n",
      "\n",
      "Epoch 00849: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7758 - val_loss: 3.4696\n",
      "Epoch 850/2000\n",
      "\n",
      "Epoch 00850: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4694\n",
      "Epoch 851/2000\n",
      "\n",
      "Epoch 00851: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7758 - val_loss: 3.4693\n",
      "Epoch 852/2000\n",
      "\n",
      "Epoch 00852: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4691\n",
      "Epoch 853/2000\n",
      "\n",
      "Epoch 00853: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4689\n",
      "Epoch 854/2000\n",
      "\n",
      "Epoch 00854: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4688\n",
      "Epoch 855/2000\n",
      "\n",
      "Epoch 00855: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4686\n",
      "Epoch 856/2000\n",
      "\n",
      "Epoch 00856: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4685\n",
      "Epoch 857/2000\n",
      "\n",
      "Epoch 00857: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7758 - val_loss: 3.4683\n",
      "Epoch 858/2000\n",
      "\n",
      "Epoch 00858: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7758 - val_loss: 3.4682\n",
      "Epoch 859/2000\n",
      "\n",
      "Epoch 00859: LearningRateScheduler reducing learning rate to tf.Tensor(8.5070646e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4680\n",
      "Epoch 860/2000\n",
      "\n",
      "Epoch 00860: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4679\n",
      "Epoch 861/2000\n",
      "\n",
      "Epoch 00861: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4678\n",
      "Epoch 862/2000\n",
      "\n",
      "Epoch 00862: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7758 - val_loss: 3.4676\n",
      "Epoch 863/2000\n",
      "\n",
      "Epoch 00863: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4675\n",
      "Epoch 864/2000\n",
      "\n",
      "Epoch 00864: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7758 - val_loss: 3.4674\n",
      "Epoch 865/2000\n",
      "\n",
      "Epoch 00865: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4673\n",
      "Epoch 866/2000\n",
      "\n",
      "Epoch 00866: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4672\n",
      "Epoch 867/2000\n",
      "\n",
      "Epoch 00867: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7758 - val_loss: 3.4671\n",
      "Epoch 868/2000\n",
      "\n",
      "Epoch 00868: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4670\n",
      "Epoch 869/2000\n",
      "\n",
      "Epoch 00869: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7758 - val_loss: 3.4669\n",
      "Epoch 870/2000\n",
      "\n",
      "Epoch 00870: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7758 - val_loss: 3.4668\n",
      "Epoch 871/2000\n",
      "\n",
      "Epoch 00871: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7757 - val_loss: 3.4667\n",
      "Epoch 872/2000\n",
      "\n",
      "Epoch 00872: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7757 - val_loss: 3.4666\n",
      "Epoch 873/2000\n",
      "\n",
      "Epoch 00873: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4665\n",
      "Epoch 874/2000\n",
      "\n",
      "Epoch 00874: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4664\n",
      "Epoch 875/2000\n",
      "\n",
      "Epoch 00875: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4663\n",
      "Epoch 876/2000\n",
      "\n",
      "Epoch 00876: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4663\n",
      "Epoch 877/2000\n",
      "\n",
      "Epoch 00877: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4662\n",
      "Epoch 878/2000\n",
      "\n",
      "Epoch 00878: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4661\n",
      "Epoch 879/2000\n",
      "\n",
      "Epoch 00879: LearningRateScheduler reducing learning rate to tf.Tensor(6.805652e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4660\n",
      "Epoch 880/2000\n",
      "\n",
      "Epoch 00880: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7757 - val_loss: 3.4660\n",
      "Epoch 881/2000\n",
      "\n",
      "Epoch 00881: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7757 - val_loss: 3.4659\n",
      "Epoch 882/2000\n",
      "\n",
      "Epoch 00882: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4658\n",
      "Epoch 883/2000\n",
      "\n",
      "Epoch 00883: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4658\n",
      "Epoch 884/2000\n",
      "\n",
      "Epoch 00884: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7757 - val_loss: 3.4657\n",
      "Epoch 885/2000\n",
      "\n",
      "Epoch 00885: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4657\n",
      "Epoch 886/2000\n",
      "\n",
      "Epoch 00886: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4656\n",
      "Epoch 887/2000\n",
      "\n",
      "Epoch 00887: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4656\n",
      "Epoch 888/2000\n",
      "\n",
      "Epoch 00888: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4655\n",
      "Epoch 889/2000\n",
      "\n",
      "Epoch 00889: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7757 - val_loss: 3.4655\n",
      "Epoch 890/2000\n",
      "\n",
      "Epoch 00890: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7757 - val_loss: 3.4655\n",
      "Epoch 891/2000\n",
      "\n",
      "Epoch 00891: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4654\n",
      "Epoch 892/2000\n",
      "\n",
      "Epoch 00892: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7757 - val_loss: 3.4654\n",
      "Epoch 893/2000\n",
      "\n",
      "Epoch 00893: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7757 - val_loss: 3.4654\n",
      "Epoch 894/2000\n",
      "\n",
      "Epoch 00894: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4653\n",
      "Epoch 895/2000\n",
      "\n",
      "Epoch 00895: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4653\n",
      "Epoch 896/2000\n",
      "\n",
      "Epoch 00896: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7757 - val_loss: 3.4653\n",
      "Epoch 897/2000\n",
      "\n",
      "Epoch 00897: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4652\n",
      "Epoch 898/2000\n",
      "\n",
      "Epoch 00898: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4652\n",
      "Epoch 899/2000\n",
      "\n",
      "Epoch 00899: LearningRateScheduler reducing learning rate to tf.Tensor(5.444522e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7757 - val_loss: 3.4652\n",
      "Epoch 900/2000\n",
      "\n",
      "Epoch 00900: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7757 - val_loss: 3.4652\n",
      "Epoch 901/2000\n",
      "\n",
      "Epoch 00901: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7757 - val_loss: 3.4652\n",
      "Epoch 902/2000\n",
      "\n",
      "Epoch 00902: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 903/2000\n",
      "\n",
      "Epoch 00903: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 904/2000\n",
      "\n",
      "Epoch 00904: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 905/2000\n",
      "\n",
      "Epoch 00905: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 906/2000\n",
      "\n",
      "Epoch 00906: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 907/2000\n",
      "\n",
      "Epoch 00907: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 908/2000\n",
      "\n",
      "Epoch 00908: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 909/2000\n",
      "\n",
      "Epoch 00909: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 910/2000\n",
      "\n",
      "Epoch 00910: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 911/2000\n",
      "\n",
      "Epoch 00911: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 912/2000\n",
      "\n",
      "Epoch 00912: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 913/2000\n",
      "\n",
      "Epoch 00913: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 914/2000\n",
      "\n",
      "Epoch 00914: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 915/2000\n",
      "\n",
      "Epoch 00915: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 916/2000\n",
      "\n",
      "Epoch 00916: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 917/2000\n",
      "\n",
      "Epoch 00917: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 918/2000\n",
      "\n",
      "Epoch 00918: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 919/2000\n",
      "\n",
      "Epoch 00919: LearningRateScheduler reducing learning rate to tf.Tensor(4.3556184e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 920/2000\n",
      "\n",
      "Epoch 00920: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 921/2000\n",
      "\n",
      "Epoch 00921: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 922/2000\n",
      "\n",
      "Epoch 00922: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 923/2000\n",
      "\n",
      "Epoch 00923: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 924/2000\n",
      "\n",
      "Epoch 00924: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 925/2000\n",
      "\n",
      "Epoch 00925: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4651\n",
      "Epoch 926/2000\n",
      "\n",
      "Epoch 00926: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 927/2000\n",
      "\n",
      "Epoch 00927: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 928/2000\n",
      "\n",
      "Epoch 00928: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 929/2000\n",
      "\n",
      "Epoch 00929: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 930/2000\n",
      "\n",
      "Epoch 00930: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 931/2000\n",
      "\n",
      "Epoch 00931: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 932/2000\n",
      "\n",
      "Epoch 00932: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.775 - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4652\n",
      "Epoch 933/2000\n",
      "\n",
      "Epoch 00933: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4653\n",
      "Epoch 934/2000\n",
      "\n",
      "Epoch 00934: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7756 - val_loss: 3.4653\n",
      "Epoch 935/2000\n",
      "\n",
      "Epoch 00935: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4653\n",
      "Epoch 936/2000\n",
      "\n",
      "Epoch 00936: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4653\n",
      "Epoch 937/2000\n",
      "\n",
      "Epoch 00937: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4653\n",
      "Epoch 938/2000\n",
      "\n",
      "Epoch 00938: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4654\n",
      "Epoch 939/2000\n",
      "\n",
      "Epoch 00939: LearningRateScheduler reducing learning rate to tf.Tensor(3.4844945e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7756 - val_loss: 3.4654\n",
      "Epoch 940/2000\n",
      "\n",
      "Epoch 00940: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7756 - val_loss: 3.4654\n",
      "Epoch 941/2000\n",
      "\n",
      "Epoch 00941: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4654\n",
      "Epoch 942/2000\n",
      "\n",
      "Epoch 00942: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7756 - val_loss: 3.4654\n",
      "Epoch 943/2000\n",
      "\n",
      "Epoch 00943: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4655\n",
      "Epoch 944/2000\n",
      "\n",
      "Epoch 00944: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4655\n",
      "Epoch 945/2000\n",
      "\n",
      "Epoch 00945: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7756 - val_loss: 3.4655\n",
      "Epoch 946/2000\n",
      "\n",
      "Epoch 00946: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7756 - val_loss: 3.4655\n",
      "Epoch 947/2000\n",
      "\n",
      "Epoch 00947: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7756 - val_loss: 3.4656\n",
      "Epoch 948/2000\n",
      "\n",
      "Epoch 00948: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4656\n",
      "Epoch 949/2000\n",
      "\n",
      "Epoch 00949: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4656\n",
      "Epoch 950/2000\n",
      "\n",
      "Epoch 00950: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4656\n",
      "Epoch 951/2000\n",
      "\n",
      "Epoch 00951: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4657\n",
      "Epoch 952/2000\n",
      "\n",
      "Epoch 00952: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4657\n",
      "Epoch 953/2000\n",
      "\n",
      "Epoch 00953: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4657\n",
      "Epoch 954/2000\n",
      "\n",
      "Epoch 00954: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4658\n",
      "Epoch 955/2000\n",
      "\n",
      "Epoch 00955: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4658\n",
      "Epoch 956/2000\n",
      "\n",
      "Epoch 00956: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4658\n",
      "Epoch 957/2000\n",
      "\n",
      "Epoch 00957: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4658\n",
      "Epoch 958/2000\n",
      "\n",
      "Epoch 00958: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4659\n",
      "Epoch 959/2000\n",
      "\n",
      "Epoch 00959: LearningRateScheduler reducing learning rate to tf.Tensor(2.7875958e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4659\n",
      "Epoch 960/2000\n",
      "\n",
      "Epoch 00960: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4659\n",
      "Epoch 961/2000\n",
      "\n",
      "Epoch 00961: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4660\n",
      "Epoch 962/2000\n",
      "\n",
      "Epoch 00962: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4660\n",
      "Epoch 963/2000\n",
      "\n",
      "Epoch 00963: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4660\n",
      "Epoch 964/2000\n",
      "\n",
      "Epoch 00964: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4660\n",
      "Epoch 965/2000\n",
      "\n",
      "Epoch 00965: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4661\n",
      "Epoch 966/2000\n",
      "\n",
      "Epoch 00966: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4661\n",
      "Epoch 967/2000\n",
      "\n",
      "Epoch 00967: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4661\n",
      "Epoch 968/2000\n",
      "\n",
      "Epoch 00968: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4662\n",
      "Epoch 969/2000\n",
      "\n",
      "Epoch 00969: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4662\n",
      "Epoch 970/2000\n",
      "\n",
      "Epoch 00970: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4662\n",
      "Epoch 971/2000\n",
      "\n",
      "Epoch 00971: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4663\n",
      "Epoch 972/2000\n",
      "\n",
      "Epoch 00972: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4663\n",
      "Epoch 973/2000\n",
      "\n",
      "Epoch 00973: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4663\n",
      "Epoch 974/2000\n",
      "\n",
      "Epoch 00974: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4663\n",
      "Epoch 975/2000\n",
      "\n",
      "Epoch 00975: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4664\n",
      "Epoch 976/2000\n",
      "\n",
      "Epoch 00976: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4664\n",
      "Epoch 977/2000\n",
      "\n",
      "Epoch 00977: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4664\n",
      "Epoch 978/2000\n",
      "\n",
      "Epoch 00978: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4665\n",
      "Epoch 979/2000\n",
      "\n",
      "Epoch 00979: LearningRateScheduler reducing learning rate to tf.Tensor(2.2300767e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4665\n",
      "Epoch 980/2000\n",
      "\n",
      "Epoch 00980: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4665\n",
      "Epoch 981/2000\n",
      "\n",
      "Epoch 00981: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4666\n",
      "Epoch 982/2000\n",
      "\n",
      "Epoch 00982: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4666\n",
      "Epoch 983/2000\n",
      "\n",
      "Epoch 00983: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4666\n",
      "Epoch 984/2000\n",
      "\n",
      "Epoch 00984: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4667\n",
      "Epoch 985/2000\n",
      "\n",
      "Epoch 00985: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4667\n",
      "Epoch 986/2000\n",
      "\n",
      "Epoch 00986: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4667\n",
      "Epoch 987/2000\n",
      "\n",
      "Epoch 00987: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4668\n",
      "Epoch 988/2000\n",
      "\n",
      "Epoch 00988: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4668\n",
      "Epoch 989/2000\n",
      "\n",
      "Epoch 00989: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4668\n",
      "Epoch 990/2000\n",
      "\n",
      "Epoch 00990: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4668\n",
      "Epoch 991/2000\n",
      "\n",
      "Epoch 00991: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.775 - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4669\n",
      "Epoch 992/2000\n",
      "\n",
      "Epoch 00992: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4669\n",
      "Epoch 993/2000\n",
      "\n",
      "Epoch 00993: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4669\n",
      "Epoch 994/2000\n",
      "\n",
      "Epoch 00994: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4670\n",
      "Epoch 995/2000\n",
      "\n",
      "Epoch 00995: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4670\n",
      "Epoch 996/2000\n",
      "\n",
      "Epoch 00996: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4670\n",
      "Epoch 997/2000\n",
      "\n",
      "Epoch 00997: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4671\n",
      "Epoch 998/2000\n",
      "\n",
      "Epoch 00998: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4671\n",
      "Epoch 999/2000\n",
      "\n",
      "Epoch 00999: LearningRateScheduler reducing learning rate to tf.Tensor(1.7840614e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4671\n",
      "Epoch 1000/2000\n",
      "\n",
      "Epoch 01000: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4672\n",
      "Epoch 1001/2000\n",
      "\n",
      "Epoch 01001: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4672\n",
      "Epoch 1002/2000\n",
      "\n",
      "Epoch 01002: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4672\n",
      "Epoch 1003/2000\n",
      "\n",
      "Epoch 01003: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4672\n",
      "Epoch 1004/2000\n",
      "\n",
      "Epoch 01004: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4673\n",
      "Epoch 1005/2000\n",
      "\n",
      "Epoch 01005: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4673\n",
      "Epoch 1006/2000\n",
      "\n",
      "Epoch 01006: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4673\n",
      "Epoch 1007/2000\n",
      "\n",
      "Epoch 01007: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4674\n",
      "Epoch 1008/2000\n",
      "\n",
      "Epoch 01008: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4674\n",
      "Epoch 1009/2000\n",
      "\n",
      "Epoch 01009: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4674\n",
      "Epoch 1010/2000\n",
      "\n",
      "Epoch 01010: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4675\n",
      "Epoch 1011/2000\n",
      "\n",
      "Epoch 01011: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4675\n",
      "Epoch 1012/2000\n",
      "\n",
      "Epoch 01012: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4675\n",
      "Epoch 1013/2000\n",
      "\n",
      "Epoch 01013: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4675\n",
      "Epoch 1014/2000\n",
      "\n",
      "Epoch 01014: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4676\n",
      "Epoch 1015/2000\n",
      "\n",
      "Epoch 01015: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4676\n",
      "Epoch 1016/2000\n",
      "\n",
      "Epoch 01016: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4676\n",
      "Epoch 1017/2000\n",
      "\n",
      "Epoch 01017: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4677\n",
      "Epoch 1018/2000\n",
      "\n",
      "Epoch 01018: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4677\n",
      "Epoch 1019/2000\n",
      "\n",
      "Epoch 01019: LearningRateScheduler reducing learning rate to tf.Tensor(1.4272493e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4677\n",
      "Epoch 1020/2000\n",
      "\n",
      "Epoch 01020: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4677\n",
      "Epoch 1021/2000\n",
      "\n",
      "Epoch 01021: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4678\n",
      "Epoch 1022/2000\n",
      "\n",
      "Epoch 01022: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4678\n",
      "Epoch 1023/2000\n",
      "\n",
      "Epoch 01023: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4678\n",
      "Epoch 1024/2000\n",
      "\n",
      "Epoch 01024: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4679\n",
      "Epoch 1025/2000\n",
      "\n",
      "Epoch 01025: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4679\n",
      "Epoch 1026/2000\n",
      "\n",
      "Epoch 01026: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4679\n",
      "Epoch 1027/2000\n",
      "\n",
      "Epoch 01027: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4679\n",
      "Epoch 1028/2000\n",
      "\n",
      "Epoch 01028: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4680\n",
      "Epoch 1029/2000\n",
      "\n",
      "Epoch 01029: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4680\n",
      "Epoch 1030/2000\n",
      "\n",
      "Epoch 01030: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4680\n",
      "Epoch 1031/2000\n",
      "\n",
      "Epoch 01031: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4681\n",
      "Epoch 1032/2000\n",
      "\n",
      "Epoch 01032: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4681\n",
      "Epoch 1033/2000\n",
      "\n",
      "Epoch 01033: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4681\n",
      "Epoch 1034/2000\n",
      "\n",
      "Epoch 01034: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4681\n",
      "Epoch 1035/2000\n",
      "\n",
      "Epoch 01035: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4682\n",
      "Epoch 1036/2000\n",
      "\n",
      "Epoch 01036: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4682\n",
      "Epoch 1037/2000\n",
      "\n",
      "Epoch 01037: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4682\n",
      "Epoch 1038/2000\n",
      "\n",
      "Epoch 01038: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4682\n",
      "Epoch 1039/2000\n",
      "\n",
      "Epoch 01039: LearningRateScheduler reducing learning rate to tf.Tensor(1.1417995e-08, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4683\n",
      "Epoch 1040/2000\n",
      "\n",
      "Epoch 01040: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4683\n",
      "Epoch 1041/2000\n",
      "\n",
      "Epoch 01041: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4683\n",
      "Epoch 1042/2000\n",
      "\n",
      "Epoch 01042: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4683\n",
      "Epoch 1043/2000\n",
      "\n",
      "Epoch 01043: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4684\n",
      "Epoch 1044/2000\n",
      "\n",
      "Epoch 01044: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4684\n",
      "Epoch 1045/2000\n",
      "\n",
      "Epoch 01045: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.7755 - val_loss: 3.4684\n",
      "Epoch 1046/2000\n",
      "\n",
      "Epoch 01046: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4684\n",
      "Epoch 1047/2000\n",
      "\n",
      "Epoch 01047: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4685\n",
      "Epoch 1048/2000\n",
      "\n",
      "Epoch 01048: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4685\n",
      "Epoch 1049/2000\n",
      "\n",
      "Epoch 01049: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4685\n",
      "Epoch 1050/2000\n",
      "\n",
      "Epoch 01050: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4685\n",
      "Epoch 1051/2000\n",
      "\n",
      "Epoch 01051: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4686\n",
      "Epoch 1052/2000\n",
      "\n",
      "Epoch 01052: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4686\n",
      "Epoch 1053/2000\n",
      "\n",
      "Epoch 01053: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4686\n",
      "Epoch 1054/2000\n",
      "\n",
      "Epoch 01054: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4686\n",
      "Epoch 1055/2000\n",
      "\n",
      "Epoch 01055: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4686\n",
      "Epoch 1056/2000\n",
      "\n",
      "Epoch 01056: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4687\n",
      "Epoch 1057/2000\n",
      "\n",
      "Epoch 01057: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4687\n",
      "Epoch 1058/2000\n",
      "\n",
      "Epoch 01058: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4687\n",
      "Epoch 1059/2000\n",
      "\n",
      "Epoch 01059: LearningRateScheduler reducing learning rate to tf.Tensor(9.1343955e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4687\n",
      "Epoch 1060/2000\n",
      "\n",
      "Epoch 01060: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4688\n",
      "Epoch 1061/2000\n",
      "\n",
      "Epoch 01061: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4688\n",
      "Epoch 1062/2000\n",
      "\n",
      "Epoch 01062: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4688\n",
      "Epoch 1063/2000\n",
      "\n",
      "Epoch 01063: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4688\n",
      "Epoch 1064/2000\n",
      "\n",
      "Epoch 01064: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4688\n",
      "Epoch 1065/2000\n",
      "\n",
      "Epoch 01065: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4689\n",
      "Epoch 1066/2000\n",
      "\n",
      "Epoch 01066: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4689\n",
      "Epoch 1067/2000\n",
      "\n",
      "Epoch 01067: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4689\n",
      "Epoch 1068/2000\n",
      "\n",
      "Epoch 01068: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4689\n",
      "Epoch 1069/2000\n",
      "\n",
      "Epoch 01069: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4690\n",
      "Epoch 1070/2000\n",
      "\n",
      "Epoch 01070: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4690\n",
      "Epoch 1071/2000\n",
      "\n",
      "Epoch 01071: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4690\n",
      "Epoch 1072/2000\n",
      "\n",
      "Epoch 01072: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4690\n",
      "Epoch 1073/2000\n",
      "\n",
      "Epoch 01073: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4690\n",
      "Epoch 1074/2000\n",
      "\n",
      "Epoch 01074: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4691\n",
      "Epoch 1075/2000\n",
      "\n",
      "Epoch 01075: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7755 - val_loss: 3.4691\n",
      "Epoch 1076/2000\n",
      "\n",
      "Epoch 01076: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4691\n",
      "Epoch 1077/2000\n",
      "\n",
      "Epoch 01077: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4691\n",
      "Epoch 1078/2000\n",
      "\n",
      "Epoch 01078: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4691\n",
      "Epoch 1079/2000\n",
      "\n",
      "Epoch 01079: LearningRateScheduler reducing learning rate to tf.Tensor(7.3075177e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4692\n",
      "Epoch 1080/2000\n",
      "\n",
      "Epoch 01080: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4692\n",
      "Epoch 1081/2000\n",
      "\n",
      "Epoch 01081: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4692\n",
      "Epoch 1082/2000\n",
      "\n",
      "Epoch 01082: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4692\n",
      "Epoch 1083/2000\n",
      "\n",
      "Epoch 01083: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4692\n",
      "Epoch 1084/2000\n",
      "\n",
      "Epoch 01084: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4692\n",
      "Epoch 1085/2000\n",
      "\n",
      "Epoch 01085: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4693\n",
      "Epoch 1086/2000\n",
      "\n",
      "Epoch 01086: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4693\n",
      "Epoch 1087/2000\n",
      "\n",
      "Epoch 01087: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4693\n",
      "Epoch 1088/2000\n",
      "\n",
      "Epoch 01088: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4693\n",
      "Epoch 1089/2000\n",
      "\n",
      "Epoch 01089: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4693\n",
      "Epoch 1090/2000\n",
      "\n",
      "Epoch 01090: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4694\n",
      "Epoch 1091/2000\n",
      "\n",
      "Epoch 01091: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4694\n",
      "Epoch 1092/2000\n",
      "\n",
      "Epoch 01092: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4694\n",
      "Epoch 1093/2000\n",
      "\n",
      "Epoch 01093: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4694\n",
      "Epoch 1094/2000\n",
      "\n",
      "Epoch 01094: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4694\n",
      "Epoch 1095/2000\n",
      "\n",
      "Epoch 01095: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4694\n",
      "Epoch 1096/2000\n",
      "\n",
      "Epoch 01096: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4695\n",
      "Epoch 1097/2000\n",
      "\n",
      "Epoch 01097: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4695\n",
      "Epoch 1098/2000\n",
      "\n",
      "Epoch 01098: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4695\n",
      "Epoch 1099/2000\n",
      "\n",
      "Epoch 01099: LearningRateScheduler reducing learning rate to tf.Tensor(5.8460086e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 3.7755 - val_loss: 3.4695\n",
      "Epoch 1100/2000\n",
      "\n",
      "Epoch 01100: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4695\n",
      "Epoch 1101/2000\n",
      "\n",
      "Epoch 01101: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4695\n",
      "Epoch 1102/2000\n",
      "\n",
      "Epoch 01102: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4696\n",
      "Epoch 1103/2000\n",
      "\n",
      "Epoch 01103: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4696\n",
      "Epoch 1104/2000\n",
      "\n",
      "Epoch 01104: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4696\n",
      "Epoch 1105/2000\n",
      "\n",
      "Epoch 01105: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4696\n",
      "Epoch 1106/2000\n",
      "\n",
      "Epoch 01106: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4696\n",
      "Epoch 1107/2000\n",
      "\n",
      "Epoch 01107: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4696\n",
      "Epoch 1108/2000\n",
      "\n",
      "Epoch 01108: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4697\n",
      "Epoch 1109/2000\n",
      "\n",
      "Epoch 01109: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4697\n",
      "Epoch 1110/2000\n",
      "\n",
      "Epoch 01110: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4697\n",
      "Epoch 1111/2000\n",
      "\n",
      "Epoch 01111: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4697\n",
      "Epoch 1112/2000\n",
      "\n",
      "Epoch 01112: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4697\n",
      "Epoch 1113/2000\n",
      "\n",
      "Epoch 01113: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4697\n",
      "Epoch 1114/2000\n",
      "\n",
      "Epoch 01114: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1115/2000\n",
      "\n",
      "Epoch 01115: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1116/2000\n",
      "\n",
      "Epoch 01116: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1117/2000\n",
      "\n",
      "Epoch 01117: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1118/2000\n",
      "\n",
      "Epoch 01118: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1119/2000\n",
      "\n",
      "Epoch 01119: LearningRateScheduler reducing learning rate to tf.Tensor(4.6768074e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1120/2000\n",
      "\n",
      "Epoch 01120: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4698\n",
      "Epoch 1121/2000\n",
      "\n",
      "Epoch 01121: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1122/2000\n",
      "\n",
      "Epoch 01122: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1123/2000\n",
      "\n",
      "Epoch 01123: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1124/2000\n",
      "\n",
      "Epoch 01124: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1125/2000\n",
      "\n",
      "Epoch 01125: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1126/2000\n",
      "\n",
      "Epoch 01126: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1127/2000\n",
      "\n",
      "Epoch 01127: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1128/2000\n",
      "\n",
      "Epoch 01128: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4699\n",
      "Epoch 1129/2000\n",
      "\n",
      "Epoch 01129: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1130/2000\n",
      "\n",
      "Epoch 01130: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1131/2000\n",
      "\n",
      "Epoch 01131: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1132/2000\n",
      "\n",
      "Epoch 01132: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1133/2000\n",
      "\n",
      "Epoch 01133: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1134/2000\n",
      "\n",
      "Epoch 01134: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1135/2000\n",
      "\n",
      "Epoch 01135: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1136/2000\n",
      "\n",
      "Epoch 01136: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4700\n",
      "Epoch 1137/2000\n",
      "\n",
      "Epoch 01137: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1138/2000\n",
      "\n",
      "Epoch 01138: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1139/2000\n",
      "\n",
      "Epoch 01139: LearningRateScheduler reducing learning rate to tf.Tensor(3.7414463e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1140/2000\n",
      "\n",
      "Epoch 01140: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1141/2000\n",
      "\n",
      "Epoch 01141: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1142/2000\n",
      "\n",
      "Epoch 01142: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1143/2000\n",
      "\n",
      "Epoch 01143: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1144/2000\n",
      "\n",
      "Epoch 01144: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4701\n",
      "Epoch 1145/2000\n",
      "\n",
      "Epoch 01145: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1146/2000\n",
      "\n",
      "Epoch 01146: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1147/2000\n",
      "\n",
      "Epoch 01147: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1148/2000\n",
      "\n",
      "Epoch 01148: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1149/2000\n",
      "\n",
      "Epoch 01149: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1150/2000\n",
      "\n",
      "Epoch 01150: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1151/2000\n",
      "\n",
      "Epoch 01151: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1152/2000\n",
      "\n",
      "Epoch 01152: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1153/2000\n",
      "\n",
      "Epoch 01153: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1154/2000\n",
      "\n",
      "Epoch 01154: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4702\n",
      "Epoch 1155/2000\n",
      "\n",
      "Epoch 01155: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1156/2000\n",
      "\n",
      "Epoch 01156: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1157/2000\n",
      "\n",
      "Epoch 01157: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1158/2000\n",
      "\n",
      "Epoch 01158: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1159/2000\n",
      "\n",
      "Epoch 01159: LearningRateScheduler reducing learning rate to tf.Tensor(2.9931573e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1160/2000\n",
      "\n",
      "Epoch 01160: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1161/2000\n",
      "\n",
      "Epoch 01161: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1162/2000\n",
      "\n",
      "Epoch 01162: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1163/2000\n",
      "\n",
      "Epoch 01163: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4703\n",
      "Epoch 1164/2000\n",
      "\n",
      "Epoch 01164: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1165/2000\n",
      "\n",
      "Epoch 01165: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1166/2000\n",
      "\n",
      "Epoch 01166: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1167/2000\n",
      "\n",
      "Epoch 01167: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1168/2000\n",
      "\n",
      "Epoch 01168: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1169/2000\n",
      "\n",
      "Epoch 01169: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1170/2000\n",
      "\n",
      "Epoch 01170: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1171/2000\n",
      "\n",
      "Epoch 01171: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1172/2000\n",
      "\n",
      "Epoch 01172: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1173/2000\n",
      "\n",
      "Epoch 01173: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1174/2000\n",
      "\n",
      "Epoch 01174: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1175/2000\n",
      "\n",
      "Epoch 01175: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4704\n",
      "Epoch 1176/2000\n",
      "\n",
      "Epoch 01176: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1177/2000\n",
      "\n",
      "Epoch 01177: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1178/2000\n",
      "\n",
      "Epoch 01178: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1179/2000\n",
      "\n",
      "Epoch 01179: LearningRateScheduler reducing learning rate to tf.Tensor(2.394526e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1180/2000\n",
      "\n",
      "Epoch 01180: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1181/2000\n",
      "\n",
      "Epoch 01181: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1182/2000\n",
      "\n",
      "Epoch 01182: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1183/2000\n",
      "\n",
      "Epoch 01183: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1184/2000\n",
      "\n",
      "Epoch 01184: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1185/2000\n",
      "\n",
      "Epoch 01185: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1186/2000\n",
      "\n",
      "Epoch 01186: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4705\n",
      "Epoch 1187/2000\n",
      "\n",
      "Epoch 01187: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1188/2000\n",
      "\n",
      "Epoch 01188: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1189/2000\n",
      "\n",
      "Epoch 01189: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1190/2000\n",
      "\n",
      "Epoch 01190: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1191/2000\n",
      "\n",
      "Epoch 01191: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1192/2000\n",
      "\n",
      "Epoch 01192: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1193/2000\n",
      "\n",
      "Epoch 01193: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1194/2000\n",
      "\n",
      "Epoch 01194: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1195/2000\n",
      "\n",
      "Epoch 01195: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1196/2000\n",
      "\n",
      "Epoch 01196: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1197/2000\n",
      "\n",
      "Epoch 01197: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1198/2000\n",
      "\n",
      "Epoch 01198: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1199/2000\n",
      "\n",
      "Epoch 01199: LearningRateScheduler reducing learning rate to tf.Tensor(1.9156208e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1200/2000\n",
      "\n",
      "Epoch 01200: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.7755 - val_loss: 3.4706\n",
      "Epoch 1201/2000\n",
      "\n",
      "Epoch 01201: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1202/2000\n",
      "\n",
      "Epoch 01202: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1203/2000\n",
      "\n",
      "Epoch 01203: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1204/2000\n",
      "\n",
      "Epoch 01204: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1205/2000\n",
      "\n",
      "Epoch 01205: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1206/2000\n",
      "\n",
      "Epoch 01206: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1207/2000\n",
      "\n",
      "Epoch 01207: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1208/2000\n",
      "\n",
      "Epoch 01208: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1209/2000\n",
      "\n",
      "Epoch 01209: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1210/2000\n",
      "\n",
      "Epoch 01210: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1211/2000\n",
      "\n",
      "Epoch 01211: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1212/2000\n",
      "\n",
      "Epoch 01212: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1213/2000\n",
      "\n",
      "Epoch 01213: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1214/2000\n",
      "\n",
      "Epoch 01214: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1215/2000\n",
      "\n",
      "Epoch 01215: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1216/2000\n",
      "\n",
      "Epoch 01216: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4707\n",
      "Epoch 1217/2000\n",
      "\n",
      "Epoch 01217: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1218/2000\n",
      "\n",
      "Epoch 01218: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1219/2000\n",
      "\n",
      "Epoch 01219: LearningRateScheduler reducing learning rate to tf.Tensor(1.5324967e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1220/2000\n",
      "\n",
      "Epoch 01220: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1221/2000\n",
      "\n",
      "Epoch 01221: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1222/2000\n",
      "\n",
      "Epoch 01222: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1223/2000\n",
      "\n",
      "Epoch 01223: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1224/2000\n",
      "\n",
      "Epoch 01224: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1225/2000\n",
      "\n",
      "Epoch 01225: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1226/2000\n",
      "\n",
      "Epoch 01226: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1227/2000\n",
      "\n",
      "Epoch 01227: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1228/2000\n",
      "\n",
      "Epoch 01228: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1229/2000\n",
      "\n",
      "Epoch 01229: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1230/2000\n",
      "\n",
      "Epoch 01230: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1231/2000\n",
      "\n",
      "Epoch 01231: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1232/2000\n",
      "\n",
      "Epoch 01232: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1233/2000\n",
      "\n",
      "Epoch 01233: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1234/2000\n",
      "\n",
      "Epoch 01234: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1235/2000\n",
      "\n",
      "Epoch 01235: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1236/2000\n",
      "\n",
      "Epoch 01236: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4708\n",
      "Epoch 1237/2000\n",
      "\n",
      "Epoch 01237: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1238/2000\n",
      "\n",
      "Epoch 01238: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1239/2000\n",
      "\n",
      "Epoch 01239: LearningRateScheduler reducing learning rate to tf.Tensor(1.2259974e-09, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1240/2000\n",
      "\n",
      "Epoch 01240: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1241/2000\n",
      "\n",
      "Epoch 01241: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1242/2000\n",
      "\n",
      "Epoch 01242: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1243/2000\n",
      "\n",
      "Epoch 01243: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1244/2000\n",
      "\n",
      "Epoch 01244: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1245/2000\n",
      "\n",
      "Epoch 01245: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1246/2000\n",
      "\n",
      "Epoch 01246: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1247/2000\n",
      "\n",
      "Epoch 01247: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1248/2000\n",
      "\n",
      "Epoch 01248: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1249/2000\n",
      "\n",
      "Epoch 01249: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1250/2000\n",
      "\n",
      "Epoch 01250: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1251/2000\n",
      "\n",
      "Epoch 01251: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1252/2000\n",
      "\n",
      "Epoch 01252: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1253/2000\n",
      "\n",
      "Epoch 01253: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1254/2000\n",
      "\n",
      "Epoch 01254: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1255/2000\n",
      "\n",
      "Epoch 01255: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1256/2000\n",
      "\n",
      "Epoch 01256: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1257/2000\n",
      "\n",
      "Epoch 01257: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1258/2000\n",
      "\n",
      "Epoch 01258: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1259/2000\n",
      "\n",
      "Epoch 01259: LearningRateScheduler reducing learning rate to tf.Tensor(9.80798e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1260/2000\n",
      "\n",
      "Epoch 01260: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4709\n",
      "Epoch 1261/2000\n",
      "\n",
      "Epoch 01261: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1262/2000\n",
      "\n",
      "Epoch 01262: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1263/2000\n",
      "\n",
      "Epoch 01263: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1264/2000\n",
      "\n",
      "Epoch 01264: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1265/2000\n",
      "\n",
      "Epoch 01265: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1266/2000\n",
      "\n",
      "Epoch 01266: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1267/2000\n",
      "\n",
      "Epoch 01267: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1268/2000\n",
      "\n",
      "Epoch 01268: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1269/2000\n",
      "\n",
      "Epoch 01269: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1270/2000\n",
      "\n",
      "Epoch 01270: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1271/2000\n",
      "\n",
      "Epoch 01271: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1272/2000\n",
      "\n",
      "Epoch 01272: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1273/2000\n",
      "\n",
      "Epoch 01273: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1274/2000\n",
      "\n",
      "Epoch 01274: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1275/2000\n",
      "\n",
      "Epoch 01275: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1276/2000\n",
      "\n",
      "Epoch 01276: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1277/2000\n",
      "\n",
      "Epoch 01277: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1278/2000\n",
      "\n",
      "Epoch 01278: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1279/2000\n",
      "\n",
      "Epoch 01279: LearningRateScheduler reducing learning rate to tf.Tensor(7.846385e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1280/2000\n",
      "\n",
      "Epoch 01280: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1281/2000\n",
      "\n",
      "Epoch 01281: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1282/2000\n",
      "\n",
      "Epoch 01282: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1283/2000\n",
      "\n",
      "Epoch 01283: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1284/2000\n",
      "\n",
      "Epoch 01284: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1285/2000\n",
      "\n",
      "Epoch 01285: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1286/2000\n",
      "\n",
      "Epoch 01286: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1287/2000\n",
      "\n",
      "Epoch 01287: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4710\n",
      "Epoch 1288/2000\n",
      "\n",
      "Epoch 01288: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1289/2000\n",
      "\n",
      "Epoch 01289: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1290/2000\n",
      "\n",
      "Epoch 01290: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1291/2000\n",
      "\n",
      "Epoch 01291: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1292/2000\n",
      "\n",
      "Epoch 01292: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1293/2000\n",
      "\n",
      "Epoch 01293: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1294/2000\n",
      "\n",
      "Epoch 01294: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1295/2000\n",
      "\n",
      "Epoch 01295: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1296/2000\n",
      "\n",
      "Epoch 01296: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1297/2000\n",
      "\n",
      "Epoch 01297: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1298/2000\n",
      "\n",
      "Epoch 01298: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1299/2000\n",
      "\n",
      "Epoch 01299: LearningRateScheduler reducing learning rate to tf.Tensor(6.2771083e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1300/2000\n",
      "\n",
      "Epoch 01300: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1301/2000\n",
      "\n",
      "Epoch 01301: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1302/2000\n",
      "\n",
      "Epoch 01302: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1303/2000\n",
      "\n",
      "Epoch 01303: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1304/2000\n",
      "\n",
      "Epoch 01304: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1305/2000\n",
      "\n",
      "Epoch 01305: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1306/2000\n",
      "\n",
      "Epoch 01306: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1307/2000\n",
      "\n",
      "Epoch 01307: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1308/2000\n",
      "\n",
      "Epoch 01308: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1309/2000\n",
      "\n",
      "Epoch 01309: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1310/2000\n",
      "\n",
      "Epoch 01310: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1311/2000\n",
      "\n",
      "Epoch 01311: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1312/2000\n",
      "\n",
      "Epoch 01312: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1313/2000\n",
      "\n",
      "Epoch 01313: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1314/2000\n",
      "\n",
      "Epoch 01314: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1315/2000\n",
      "\n",
      "Epoch 01315: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1316/2000\n",
      "\n",
      "Epoch 01316: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1317/2000\n",
      "\n",
      "Epoch 01317: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1318/2000\n",
      "\n",
      "Epoch 01318: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1319/2000\n",
      "\n",
      "Epoch 01319: LearningRateScheduler reducing learning rate to tf.Tensor(5.021687e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1320/2000\n",
      "\n",
      "Epoch 01320: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1321/2000\n",
      "\n",
      "Epoch 01321: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4711\n",
      "Epoch 1322/2000\n",
      "\n",
      "Epoch 01322: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1323/2000\n",
      "\n",
      "Epoch 01323: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1324/2000\n",
      "\n",
      "Epoch 01324: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1325/2000\n",
      "\n",
      "Epoch 01325: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1326/2000\n",
      "\n",
      "Epoch 01326: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1327/2000\n",
      "\n",
      "Epoch 01327: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1328/2000\n",
      "\n",
      "Epoch 01328: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.775 - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1329/2000\n",
      "\n",
      "Epoch 01329: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1330/2000\n",
      "\n",
      "Epoch 01330: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1331/2000\n",
      "\n",
      "Epoch 01331: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1332/2000\n",
      "\n",
      "Epoch 01332: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1333/2000\n",
      "\n",
      "Epoch 01333: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1334/2000\n",
      "\n",
      "Epoch 01334: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1335/2000\n",
      "\n",
      "Epoch 01335: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1336/2000\n",
      "\n",
      "Epoch 01336: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1337/2000\n",
      "\n",
      "Epoch 01337: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1338/2000\n",
      "\n",
      "Epoch 01338: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1339/2000\n",
      "\n",
      "Epoch 01339: LearningRateScheduler reducing learning rate to tf.Tensor(4.0173495e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1340/2000\n",
      "\n",
      "Epoch 01340: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1341/2000\n",
      "\n",
      "Epoch 01341: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1342/2000\n",
      "\n",
      "Epoch 01342: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1343/2000\n",
      "\n",
      "Epoch 01343: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1344/2000\n",
      "\n",
      "Epoch 01344: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1345/2000\n",
      "\n",
      "Epoch 01345: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1346/2000\n",
      "\n",
      "Epoch 01346: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1347/2000\n",
      "\n",
      "Epoch 01347: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1348/2000\n",
      "\n",
      "Epoch 01348: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1349/2000\n",
      "\n",
      "Epoch 01349: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1350/2000\n",
      "\n",
      "Epoch 01350: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1351/2000\n",
      "\n",
      "Epoch 01351: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1352/2000\n",
      "\n",
      "Epoch 01352: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1353/2000\n",
      "\n",
      "Epoch 01353: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1354/2000\n",
      "\n",
      "Epoch 01354: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1355/2000\n",
      "\n",
      "Epoch 01355: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1356/2000\n",
      "\n",
      "Epoch 01356: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1357/2000\n",
      "\n",
      "Epoch 01357: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1358/2000\n",
      "\n",
      "Epoch 01358: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1359/2000\n",
      "\n",
      "Epoch 01359: LearningRateScheduler reducing learning rate to tf.Tensor(3.21388e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1360/2000\n",
      "\n",
      "Epoch 01360: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1361/2000\n",
      "\n",
      "Epoch 01361: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1362/2000\n",
      "\n",
      "Epoch 01362: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1363/2000\n",
      "\n",
      "Epoch 01363: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1364/2000\n",
      "\n",
      "Epoch 01364: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1365/2000\n",
      "\n",
      "Epoch 01365: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1366/2000\n",
      "\n",
      "Epoch 01366: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1367/2000\n",
      "\n",
      "Epoch 01367: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1368/2000\n",
      "\n",
      "Epoch 01368: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1369/2000\n",
      "\n",
      "Epoch 01369: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1370/2000\n",
      "\n",
      "Epoch 01370: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1371/2000\n",
      "\n",
      "Epoch 01371: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1372/2000\n",
      "\n",
      "Epoch 01372: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1373/2000\n",
      "\n",
      "Epoch 01373: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1374/2000\n",
      "\n",
      "Epoch 01374: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1375/2000\n",
      "\n",
      "Epoch 01375: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4712\n",
      "Epoch 1376/2000\n",
      "\n",
      "Epoch 01376: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1377/2000\n",
      "\n",
      "Epoch 01377: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1378/2000\n",
      "\n",
      "Epoch 01378: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1379/2000\n",
      "\n",
      "Epoch 01379: LearningRateScheduler reducing learning rate to tf.Tensor(2.571104e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1380/2000\n",
      "\n",
      "Epoch 01380: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1381/2000\n",
      "\n",
      "Epoch 01381: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1382/2000\n",
      "\n",
      "Epoch 01382: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1383/2000\n",
      "\n",
      "Epoch 01383: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1384/2000\n",
      "\n",
      "Epoch 01384: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1385/2000\n",
      "\n",
      "Epoch 01385: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1386/2000\n",
      "\n",
      "Epoch 01386: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1387/2000\n",
      "\n",
      "Epoch 01387: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1388/2000\n",
      "\n",
      "Epoch 01388: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1389/2000\n",
      "\n",
      "Epoch 01389: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1390/2000\n",
      "\n",
      "Epoch 01390: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1391/2000\n",
      "\n",
      "Epoch 01391: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1392/2000\n",
      "\n",
      "Epoch 01392: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1393/2000\n",
      "\n",
      "Epoch 01393: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1394/2000\n",
      "\n",
      "Epoch 01394: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1395/2000\n",
      "\n",
      "Epoch 01395: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1396/2000\n",
      "\n",
      "Epoch 01396: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1397/2000\n",
      "\n",
      "Epoch 01397: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1398/2000\n",
      "\n",
      "Epoch 01398: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1399/2000\n",
      "\n",
      "Epoch 01399: LearningRateScheduler reducing learning rate to tf.Tensor(2.0568833e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1400/2000\n",
      "\n",
      "Epoch 01400: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1401/2000\n",
      "\n",
      "Epoch 01401: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1402/2000\n",
      "\n",
      "Epoch 01402: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1403/2000\n",
      "\n",
      "Epoch 01403: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1404/2000\n",
      "\n",
      "Epoch 01404: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1405/2000\n",
      "\n",
      "Epoch 01405: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1406/2000\n",
      "\n",
      "Epoch 01406: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1407/2000\n",
      "\n",
      "Epoch 01407: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1408/2000\n",
      "\n",
      "Epoch 01408: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1409/2000\n",
      "\n",
      "Epoch 01409: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1410/2000\n",
      "\n",
      "Epoch 01410: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1411/2000\n",
      "\n",
      "Epoch 01411: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1412/2000\n",
      "\n",
      "Epoch 01412: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1413/2000\n",
      "\n",
      "Epoch 01413: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1414/2000\n",
      "\n",
      "Epoch 01414: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1415/2000\n",
      "\n",
      "Epoch 01415: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1416/2000\n",
      "\n",
      "Epoch 01416: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1417/2000\n",
      "\n",
      "Epoch 01417: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1418/2000\n",
      "\n",
      "Epoch 01418: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1419/2000\n",
      "\n",
      "Epoch 01419: LearningRateScheduler reducing learning rate to tf.Tensor(1.6455066e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1420/2000\n",
      "\n",
      "Epoch 01420: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1421/2000\n",
      "\n",
      "Epoch 01421: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1422/2000\n",
      "\n",
      "Epoch 01422: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1423/2000\n",
      "\n",
      "Epoch 01423: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1424/2000\n",
      "\n",
      "Epoch 01424: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1425/2000\n",
      "\n",
      "Epoch 01425: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1426/2000\n",
      "\n",
      "Epoch 01426: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1427/2000\n",
      "\n",
      "Epoch 01427: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1428/2000\n",
      "\n",
      "Epoch 01428: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1429/2000\n",
      "\n",
      "Epoch 01429: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.775 - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1430/2000\n",
      "\n",
      "Epoch 01430: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1431/2000\n",
      "\n",
      "Epoch 01431: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1432/2000\n",
      "\n",
      "Epoch 01432: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1433/2000\n",
      "\n",
      "Epoch 01433: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1434/2000\n",
      "\n",
      "Epoch 01434: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1435/2000\n",
      "\n",
      "Epoch 01435: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1436/2000\n",
      "\n",
      "Epoch 01436: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1437/2000\n",
      "\n",
      "Epoch 01437: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1438/2000\n",
      "\n",
      "Epoch 01438: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1439/2000\n",
      "\n",
      "Epoch 01439: LearningRateScheduler reducing learning rate to tf.Tensor(1.3164056e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1440/2000\n",
      "\n",
      "Epoch 01440: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1441/2000\n",
      "\n",
      "Epoch 01441: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1442/2000\n",
      "\n",
      "Epoch 01442: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1443/2000\n",
      "\n",
      "Epoch 01443: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1444/2000\n",
      "\n",
      "Epoch 01444: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1445/2000\n",
      "\n",
      "Epoch 01445: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1446/2000\n",
      "\n",
      "Epoch 01446: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1447/2000\n",
      "\n",
      "Epoch 01447: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1448/2000\n",
      "\n",
      "Epoch 01448: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1449/2000\n",
      "\n",
      "Epoch 01449: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1450/2000\n",
      "\n",
      "Epoch 01450: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1451/2000\n",
      "\n",
      "Epoch 01451: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1452/2000\n",
      "\n",
      "Epoch 01452: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1453/2000\n",
      "\n",
      "Epoch 01453: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1454/2000\n",
      "\n",
      "Epoch 01454: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1455/2000\n",
      "\n",
      "Epoch 01455: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1456/2000\n",
      "\n",
      "Epoch 01456: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1457/2000\n",
      "\n",
      "Epoch 01457: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1458/2000\n",
      "\n",
      "Epoch 01458: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1459/2000\n",
      "\n",
      "Epoch 01459: LearningRateScheduler reducing learning rate to tf.Tensor(1.0531234e-10, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1460/2000\n",
      "\n",
      "Epoch 01460: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1461/2000\n",
      "\n",
      "Epoch 01461: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1462/2000\n",
      "\n",
      "Epoch 01462: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1463/2000\n",
      "\n",
      "Epoch 01463: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1464/2000\n",
      "\n",
      "Epoch 01464: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1465/2000\n",
      "\n",
      "Epoch 01465: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1466/2000\n",
      "\n",
      "Epoch 01466: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1467/2000\n",
      "\n",
      "Epoch 01467: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1468/2000\n",
      "\n",
      "Epoch 01468: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1469/2000\n",
      "\n",
      "Epoch 01469: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1470/2000\n",
      "\n",
      "Epoch 01470: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1471/2000\n",
      "\n",
      "Epoch 01471: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1472/2000\n",
      "\n",
      "Epoch 01472: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1473/2000\n",
      "\n",
      "Epoch 01473: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1474/2000\n",
      "\n",
      "Epoch 01474: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1475/2000\n",
      "\n",
      "Epoch 01475: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1476/2000\n",
      "\n",
      "Epoch 01476: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1477/2000\n",
      "\n",
      "Epoch 01477: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1478/2000\n",
      "\n",
      "Epoch 01478: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1479/2000\n",
      "\n",
      "Epoch 01479: LearningRateScheduler reducing learning rate to tf.Tensor(8.424997e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1480/2000\n",
      "\n",
      "Epoch 01480: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1481/2000\n",
      "\n",
      "Epoch 01481: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1482/2000\n",
      "\n",
      "Epoch 01482: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1483/2000\n",
      "\n",
      "Epoch 01483: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1484/2000\n",
      "\n",
      "Epoch 01484: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1485/2000\n",
      "\n",
      "Epoch 01485: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1486/2000\n",
      "\n",
      "Epoch 01486: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1487/2000\n",
      "\n",
      "Epoch 01487: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1488/2000\n",
      "\n",
      "Epoch 01488: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1489/2000\n",
      "\n",
      "Epoch 01489: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1490/2000\n",
      "\n",
      "Epoch 01490: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1491/2000\n",
      "\n",
      "Epoch 01491: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1492/2000\n",
      "\n",
      "Epoch 01492: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1493/2000\n",
      "\n",
      "Epoch 01493: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1494/2000\n",
      "\n",
      "Epoch 01494: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1495/2000\n",
      "\n",
      "Epoch 01495: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1496/2000\n",
      "\n",
      "Epoch 01496: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1497/2000\n",
      "\n",
      "Epoch 01497: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1498/2000\n",
      "\n",
      "Epoch 01498: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4713\n",
      "Epoch 1499/2000\n",
      "\n",
      "Epoch 01499: LearningRateScheduler reducing learning rate to tf.Tensor(6.7399905e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1500/2000\n",
      "\n",
      "Epoch 01500: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1501/2000\n",
      "\n",
      "Epoch 01501: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1502/2000\n",
      "\n",
      "Epoch 01502: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1503/2000\n",
      "\n",
      "Epoch 01503: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1504/2000\n",
      "\n",
      "Epoch 01504: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1505/2000\n",
      "\n",
      "Epoch 01505: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1506/2000\n",
      "\n",
      "Epoch 01506: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1507/2000\n",
      "\n",
      "Epoch 01507: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1508/2000\n",
      "\n",
      "Epoch 01508: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1509/2000\n",
      "\n",
      "Epoch 01509: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1510/2000\n",
      "\n",
      "Epoch 01510: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1511/2000\n",
      "\n",
      "Epoch 01511: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1512/2000\n",
      "\n",
      "Epoch 01512: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1513/2000\n",
      "\n",
      "Epoch 01513: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1514/2000\n",
      "\n",
      "Epoch 01514: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1515/2000\n",
      "\n",
      "Epoch 01515: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1516/2000\n",
      "\n",
      "Epoch 01516: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1517/2000\n",
      "\n",
      "Epoch 01517: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1518/2000\n",
      "\n",
      "Epoch 01518: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1519/2000\n",
      "\n",
      "Epoch 01519: LearningRateScheduler reducing learning rate to tf.Tensor(5.3919983e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1520/2000\n",
      "\n",
      "Epoch 01520: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1521/2000\n",
      "\n",
      "Epoch 01521: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1522/2000\n",
      "\n",
      "Epoch 01522: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1523/2000\n",
      "\n",
      "Epoch 01523: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1524/2000\n",
      "\n",
      "Epoch 01524: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1525/2000\n",
      "\n",
      "Epoch 01525: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1526/2000\n",
      "\n",
      "Epoch 01526: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1527/2000\n",
      "\n",
      "Epoch 01527: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1528/2000\n",
      "\n",
      "Epoch 01528: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1529/2000\n",
      "\n",
      "Epoch 01529: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1530/2000\n",
      "\n",
      "Epoch 01530: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1531/2000\n",
      "\n",
      "Epoch 01531: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1532/2000\n",
      "\n",
      "Epoch 01532: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1533/2000\n",
      "\n",
      "Epoch 01533: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1534/2000\n",
      "\n",
      "Epoch 01534: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1535/2000\n",
      "\n",
      "Epoch 01535: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1536/2000\n",
      "\n",
      "Epoch 01536: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1537/2000\n",
      "\n",
      "Epoch 01537: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1538/2000\n",
      "\n",
      "Epoch 01538: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1539/2000\n",
      "\n",
      "Epoch 01539: LearningRateScheduler reducing learning rate to tf.Tensor(4.3135946e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1540/2000\n",
      "\n",
      "Epoch 01540: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1541/2000\n",
      "\n",
      "Epoch 01541: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1542/2000\n",
      "\n",
      "Epoch 01542: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1543/2000\n",
      "\n",
      "Epoch 01543: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1544/2000\n",
      "\n",
      "Epoch 01544: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1545/2000\n",
      "\n",
      "Epoch 01545: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1546/2000\n",
      "\n",
      "Epoch 01546: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1547/2000\n",
      "\n",
      "Epoch 01547: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1548/2000\n",
      "\n",
      "Epoch 01548: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1549/2000\n",
      "\n",
      "Epoch 01549: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1550/2000\n",
      "\n",
      "Epoch 01550: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1551/2000\n",
      "\n",
      "Epoch 01551: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1552/2000\n",
      "\n",
      "Epoch 01552: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1553/2000\n",
      "\n",
      "Epoch 01553: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1554/2000\n",
      "\n",
      "Epoch 01554: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1555/2000\n",
      "\n",
      "Epoch 01555: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1556/2000\n",
      "\n",
      "Epoch 01556: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1557/2000\n",
      "\n",
      "Epoch 01557: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1558/2000\n",
      "\n",
      "Epoch 01558: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1559/2000\n",
      "\n",
      "Epoch 01559: LearningRateScheduler reducing learning rate to tf.Tensor(3.4508795e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1560/2000\n",
      "\n",
      "Epoch 01560: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1561/2000\n",
      "\n",
      "Epoch 01561: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1562/2000\n",
      "\n",
      "Epoch 01562: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1563/2000\n",
      "\n",
      "Epoch 01563: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1564/2000\n",
      "\n",
      "Epoch 01564: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1565/2000\n",
      "\n",
      "Epoch 01565: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1566/2000\n",
      "\n",
      "Epoch 01566: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1567/2000\n",
      "\n",
      "Epoch 01567: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1568/2000\n",
      "\n",
      "Epoch 01568: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1569/2000\n",
      "\n",
      "Epoch 01569: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1570/2000\n",
      "\n",
      "Epoch 01570: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1571/2000\n",
      "\n",
      "Epoch 01571: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1572/2000\n",
      "\n",
      "Epoch 01572: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1573/2000\n",
      "\n",
      "Epoch 01573: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1574/2000\n",
      "\n",
      "Epoch 01574: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1575/2000\n",
      "\n",
      "Epoch 01575: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1576/2000\n",
      "\n",
      "Epoch 01576: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1577/2000\n",
      "\n",
      "Epoch 01577: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1578/2000\n",
      "\n",
      "Epoch 01578: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1579/2000\n",
      "\n",
      "Epoch 01579: LearningRateScheduler reducing learning rate to tf.Tensor(2.7607012e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1580/2000\n",
      "\n",
      "Epoch 01580: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1581/2000\n",
      "\n",
      "Epoch 01581: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1582/2000\n",
      "\n",
      "Epoch 01582: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1583/2000\n",
      "\n",
      "Epoch 01583: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1584/2000\n",
      "\n",
      "Epoch 01584: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1585/2000\n",
      "\n",
      "Epoch 01585: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1586/2000\n",
      "\n",
      "Epoch 01586: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1587/2000\n",
      "\n",
      "Epoch 01587: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1588/2000\n",
      "\n",
      "Epoch 01588: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1589/2000\n",
      "\n",
      "Epoch 01589: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1590/2000\n",
      "\n",
      "Epoch 01590: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1591/2000\n",
      "\n",
      "Epoch 01591: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1592/2000\n",
      "\n",
      "Epoch 01592: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1593/2000\n",
      "\n",
      "Epoch 01593: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1594/2000\n",
      "\n",
      "Epoch 01594: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1595/2000\n",
      "\n",
      "Epoch 01595: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1596/2000\n",
      "\n",
      "Epoch 01596: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1597/2000\n",
      "\n",
      "Epoch 01597: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1598/2000\n",
      "\n",
      "Epoch 01598: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1599/2000\n",
      "\n",
      "Epoch 01599: LearningRateScheduler reducing learning rate to tf.Tensor(2.208563e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1600/2000\n",
      "\n",
      "Epoch 01600: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1601/2000\n",
      "\n",
      "Epoch 01601: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1602/2000\n",
      "\n",
      "Epoch 01602: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1603/2000\n",
      "\n",
      "Epoch 01603: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1604/2000\n",
      "\n",
      "Epoch 01604: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1605/2000\n",
      "\n",
      "Epoch 01605: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1606/2000\n",
      "\n",
      "Epoch 01606: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1607/2000\n",
      "\n",
      "Epoch 01607: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1608/2000\n",
      "\n",
      "Epoch 01608: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1609/2000\n",
      "\n",
      "Epoch 01609: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1610/2000\n",
      "\n",
      "Epoch 01610: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1611/2000\n",
      "\n",
      "Epoch 01611: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1612/2000\n",
      "\n",
      "Epoch 01612: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1613/2000\n",
      "\n",
      "Epoch 01613: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1614/2000\n",
      "\n",
      "Epoch 01614: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1615/2000\n",
      "\n",
      "Epoch 01615: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1616/2000\n",
      "\n",
      "Epoch 01616: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1617/2000\n",
      "\n",
      "Epoch 01617: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1618/2000\n",
      "\n",
      "Epoch 01618: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1619/2000\n",
      "\n",
      "Epoch 01619: LearningRateScheduler reducing learning rate to tf.Tensor(1.766849e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1620/2000\n",
      "\n",
      "Epoch 01620: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1621/2000\n",
      "\n",
      "Epoch 01621: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1622/2000\n",
      "\n",
      "Epoch 01622: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1623/2000\n",
      "\n",
      "Epoch 01623: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1624/2000\n",
      "\n",
      "Epoch 01624: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1625/2000\n",
      "\n",
      "Epoch 01625: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1626/2000\n",
      "\n",
      "Epoch 01626: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1627/2000\n",
      "\n",
      "Epoch 01627: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1628/2000\n",
      "\n",
      "Epoch 01628: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1629/2000\n",
      "\n",
      "Epoch 01629: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1630/2000\n",
      "\n",
      "Epoch 01630: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1631/2000\n",
      "\n",
      "Epoch 01631: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1632/2000\n",
      "\n",
      "Epoch 01632: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1633/2000\n",
      "\n",
      "Epoch 01633: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1634/2000\n",
      "\n",
      "Epoch 01634: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1635/2000\n",
      "\n",
      "Epoch 01635: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1636/2000\n",
      "\n",
      "Epoch 01636: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1637/2000\n",
      "\n",
      "Epoch 01637: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1638/2000\n",
      "\n",
      "Epoch 01638: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1639/2000\n",
      "\n",
      "Epoch 01639: LearningRateScheduler reducing learning rate to tf.Tensor(1.4134804e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1640/2000\n",
      "\n",
      "Epoch 01640: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1641/2000\n",
      "\n",
      "Epoch 01641: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1642/2000\n",
      "\n",
      "Epoch 01642: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1643/2000\n",
      "\n",
      "Epoch 01643: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1644/2000\n",
      "\n",
      "Epoch 01644: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1645/2000\n",
      "\n",
      "Epoch 01645: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1646/2000\n",
      "\n",
      "Epoch 01646: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1647/2000\n",
      "\n",
      "Epoch 01647: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1648/2000\n",
      "\n",
      "Epoch 01648: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1649/2000\n",
      "\n",
      "Epoch 01649: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1650/2000\n",
      "\n",
      "Epoch 01650: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1651/2000\n",
      "\n",
      "Epoch 01651: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1652/2000\n",
      "\n",
      "Epoch 01652: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1653/2000\n",
      "\n",
      "Epoch 01653: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1654/2000\n",
      "\n",
      "Epoch 01654: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1655/2000\n",
      "\n",
      "Epoch 01655: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1656/2000\n",
      "\n",
      "Epoch 01656: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1657/2000\n",
      "\n",
      "Epoch 01657: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1658/2000\n",
      "\n",
      "Epoch 01658: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1659/2000\n",
      "\n",
      "Epoch 01659: LearningRateScheduler reducing learning rate to tf.Tensor(1.1307834e-11, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1660/2000\n",
      "\n",
      "Epoch 01660: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1661/2000\n",
      "\n",
      "Epoch 01661: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1662/2000\n",
      "\n",
      "Epoch 01662: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1663/2000\n",
      "\n",
      "Epoch 01663: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1664/2000\n",
      "\n",
      "Epoch 01664: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1665/2000\n",
      "\n",
      "Epoch 01665: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1666/2000\n",
      "\n",
      "Epoch 01666: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1667/2000\n",
      "\n",
      "Epoch 01667: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1668/2000\n",
      "\n",
      "Epoch 01668: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1669/2000\n",
      "\n",
      "Epoch 01669: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1670/2000\n",
      "\n",
      "Epoch 01670: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1671/2000\n",
      "\n",
      "Epoch 01671: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1672/2000\n",
      "\n",
      "Epoch 01672: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1673/2000\n",
      "\n",
      "Epoch 01673: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1674/2000\n",
      "\n",
      "Epoch 01674: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1675/2000\n",
      "\n",
      "Epoch 01675: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1676/2000\n",
      "\n",
      "Epoch 01676: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1677/2000\n",
      "\n",
      "Epoch 01677: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1678/2000\n",
      "\n",
      "Epoch 01678: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1679/2000\n",
      "\n",
      "Epoch 01679: LearningRateScheduler reducing learning rate to tf.Tensor(9.046276e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1680/2000\n",
      "\n",
      "Epoch 01680: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1681/2000\n",
      "\n",
      "Epoch 01681: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1682/2000\n",
      "\n",
      "Epoch 01682: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1683/2000\n",
      "\n",
      "Epoch 01683: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1684/2000\n",
      "\n",
      "Epoch 01684: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1685/2000\n",
      "\n",
      "Epoch 01685: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1686/2000\n",
      "\n",
      "Epoch 01686: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1687/2000\n",
      "\n",
      "Epoch 01687: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1688/2000\n",
      "\n",
      "Epoch 01688: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1689/2000\n",
      "\n",
      "Epoch 01689: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1690/2000\n",
      "\n",
      "Epoch 01690: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1691/2000\n",
      "\n",
      "Epoch 01691: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1692/2000\n",
      "\n",
      "Epoch 01692: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1693/2000\n",
      "\n",
      "Epoch 01693: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1694/2000\n",
      "\n",
      "Epoch 01694: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1695/2000\n",
      "\n",
      "Epoch 01695: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1696/2000\n",
      "\n",
      "Epoch 01696: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1697/2000\n",
      "\n",
      "Epoch 01697: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1698/2000\n",
      "\n",
      "Epoch 01698: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1699/2000\n",
      "\n",
      "Epoch 01699: LearningRateScheduler reducing learning rate to tf.Tensor(7.237014e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1700/2000\n",
      "\n",
      "Epoch 01700: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1701/2000\n",
      "\n",
      "Epoch 01701: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1702/2000\n",
      "\n",
      "Epoch 01702: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1703/2000\n",
      "\n",
      "Epoch 01703: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1704/2000\n",
      "\n",
      "Epoch 01704: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1705/2000\n",
      "\n",
      "Epoch 01705: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1706/2000\n",
      "\n",
      "Epoch 01706: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1707/2000\n",
      "\n",
      "Epoch 01707: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1708/2000\n",
      "\n",
      "Epoch 01708: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1709/2000\n",
      "\n",
      "Epoch 01709: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1710/2000\n",
      "\n",
      "Epoch 01710: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1711/2000\n",
      "\n",
      "Epoch 01711: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1712/2000\n",
      "\n",
      "Epoch 01712: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1713/2000\n",
      "\n",
      "Epoch 01713: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1714/2000\n",
      "\n",
      "Epoch 01714: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1715/2000\n",
      "\n",
      "Epoch 01715: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1716/2000\n",
      "\n",
      "Epoch 01716: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1717/2000\n",
      "\n",
      "Epoch 01717: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1718/2000\n",
      "\n",
      "Epoch 01718: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1719/2000\n",
      "\n",
      "Epoch 01719: LearningRateScheduler reducing learning rate to tf.Tensor(5.789618e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1720/2000\n",
      "\n",
      "Epoch 01720: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1721/2000\n",
      "\n",
      "Epoch 01721: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1722/2000\n",
      "\n",
      "Epoch 01722: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1723/2000\n",
      "\n",
      "Epoch 01723: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1724/2000\n",
      "\n",
      "Epoch 01724: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1725/2000\n",
      "\n",
      "Epoch 01725: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1726/2000\n",
      "\n",
      "Epoch 01726: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1727/2000\n",
      "\n",
      "Epoch 01727: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1728/2000\n",
      "\n",
      "Epoch 01728: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1729/2000\n",
      "\n",
      "Epoch 01729: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1730/2000\n",
      "\n",
      "Epoch 01730: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1731/2000\n",
      "\n",
      "Epoch 01731: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1732/2000\n",
      "\n",
      "Epoch 01732: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1733/2000\n",
      "\n",
      "Epoch 01733: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1734/2000\n",
      "\n",
      "Epoch 01734: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1735/2000\n",
      "\n",
      "Epoch 01735: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1736/2000\n",
      "\n",
      "Epoch 01736: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1737/2000\n",
      "\n",
      "Epoch 01737: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1738/2000\n",
      "\n",
      "Epoch 01738: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1739/2000\n",
      "\n",
      "Epoch 01739: LearningRateScheduler reducing learning rate to tf.Tensor(4.63169e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1740/2000\n",
      "\n",
      "Epoch 01740: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1741/2000\n",
      "\n",
      "Epoch 01741: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1742/2000\n",
      "\n",
      "Epoch 01742: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1743/2000\n",
      "\n",
      "Epoch 01743: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1744/2000\n",
      "\n",
      "Epoch 01744: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1745/2000\n",
      "\n",
      "Epoch 01745: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1746/2000\n",
      "\n",
      "Epoch 01746: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1747/2000\n",
      "\n",
      "Epoch 01747: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1748/2000\n",
      "\n",
      "Epoch 01748: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1749/2000\n",
      "\n",
      "Epoch 01749: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1750/2000\n",
      "\n",
      "Epoch 01750: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1751/2000\n",
      "\n",
      "Epoch 01751: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1752/2000\n",
      "\n",
      "Epoch 01752: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1753/2000\n",
      "\n",
      "Epoch 01753: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1754/2000\n",
      "\n",
      "Epoch 01754: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1755/2000\n",
      "\n",
      "Epoch 01755: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1756/2000\n",
      "\n",
      "Epoch 01756: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1757/2000\n",
      "\n",
      "Epoch 01757: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1758/2000\n",
      "\n",
      "Epoch 01758: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1759/2000\n",
      "\n",
      "Epoch 01759: LearningRateScheduler reducing learning rate to tf.Tensor(3.7053485e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1760/2000\n",
      "\n",
      "Epoch 01760: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1761/2000\n",
      "\n",
      "Epoch 01761: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1762/2000\n",
      "\n",
      "Epoch 01762: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1763/2000\n",
      "\n",
      "Epoch 01763: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1764/2000\n",
      "\n",
      "Epoch 01764: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1765/2000\n",
      "\n",
      "Epoch 01765: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1766/2000\n",
      "\n",
      "Epoch 01766: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1767/2000\n",
      "\n",
      "Epoch 01767: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1768/2000\n",
      "\n",
      "Epoch 01768: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1769/2000\n",
      "\n",
      "Epoch 01769: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1770/2000\n",
      "\n",
      "Epoch 01770: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1771/2000\n",
      "\n",
      "Epoch 01771: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1772/2000\n",
      "\n",
      "Epoch 01772: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1773/2000\n",
      "\n",
      "Epoch 01773: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.775 - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1774/2000\n",
      "\n",
      "Epoch 01774: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1775/2000\n",
      "\n",
      "Epoch 01775: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1776/2000\n",
      "\n",
      "Epoch 01776: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1777/2000\n",
      "\n",
      "Epoch 01777: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1778/2000\n",
      "\n",
      "Epoch 01778: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1779/2000\n",
      "\n",
      "Epoch 01779: LearningRateScheduler reducing learning rate to tf.Tensor(2.9642816e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1780/2000\n",
      "\n",
      "Epoch 01780: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1781/2000\n",
      "\n",
      "Epoch 01781: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1782/2000\n",
      "\n",
      "Epoch 01782: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1783/2000\n",
      "\n",
      "Epoch 01783: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1784/2000\n",
      "\n",
      "Epoch 01784: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1785/2000\n",
      "\n",
      "Epoch 01785: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1786/2000\n",
      "\n",
      "Epoch 01786: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1787/2000\n",
      "\n",
      "Epoch 01787: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1788/2000\n",
      "\n",
      "Epoch 01788: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1789/2000\n",
      "\n",
      "Epoch 01789: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1790/2000\n",
      "\n",
      "Epoch 01790: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1791/2000\n",
      "\n",
      "Epoch 01791: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1792/2000\n",
      "\n",
      "Epoch 01792: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1793/2000\n",
      "\n",
      "Epoch 01793: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1794/2000\n",
      "\n",
      "Epoch 01794: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1795/2000\n",
      "\n",
      "Epoch 01795: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1796/2000\n",
      "\n",
      "Epoch 01796: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1797/2000\n",
      "\n",
      "Epoch 01797: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1798/2000\n",
      "\n",
      "Epoch 01798: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1799/2000\n",
      "\n",
      "Epoch 01799: LearningRateScheduler reducing learning rate to tf.Tensor(2.3714234e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1800/2000\n",
      "\n",
      "Epoch 01800: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1801/2000\n",
      "\n",
      "Epoch 01801: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1802/2000\n",
      "\n",
      "Epoch 01802: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1803/2000\n",
      "\n",
      "Epoch 01803: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1804/2000\n",
      "\n",
      "Epoch 01804: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1805/2000\n",
      "\n",
      "Epoch 01805: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1806/2000\n",
      "\n",
      "Epoch 01806: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1807/2000\n",
      "\n",
      "Epoch 01807: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1808/2000\n",
      "\n",
      "Epoch 01808: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1809/2000\n",
      "\n",
      "Epoch 01809: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1810/2000\n",
      "\n",
      "Epoch 01810: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1811/2000\n",
      "\n",
      "Epoch 01811: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1812/2000\n",
      "\n",
      "Epoch 01812: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1813/2000\n",
      "\n",
      "Epoch 01813: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1814/2000\n",
      "\n",
      "Epoch 01814: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1815/2000\n",
      "\n",
      "Epoch 01815: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1816/2000\n",
      "\n",
      "Epoch 01816: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1817/2000\n",
      "\n",
      "Epoch 01817: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1818/2000\n",
      "\n",
      "Epoch 01818: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1819/2000\n",
      "\n",
      "Epoch 01819: LearningRateScheduler reducing learning rate to tf.Tensor(1.8971409e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1820/2000\n",
      "\n",
      "Epoch 01820: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1821/2000\n",
      "\n",
      "Epoch 01821: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1822/2000\n",
      "\n",
      "Epoch 01822: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1823/2000\n",
      "\n",
      "Epoch 01823: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1824/2000\n",
      "\n",
      "Epoch 01824: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1825/2000\n",
      "\n",
      "Epoch 01825: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1826/2000\n",
      "\n",
      "Epoch 01826: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1827/2000\n",
      "\n",
      "Epoch 01827: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1828/2000\n",
      "\n",
      "Epoch 01828: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1829/2000\n",
      "\n",
      "Epoch 01829: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1830/2000\n",
      "\n",
      "Epoch 01830: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1831/2000\n",
      "\n",
      "Epoch 01831: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1832/2000\n",
      "\n",
      "Epoch 01832: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1833/2000\n",
      "\n",
      "Epoch 01833: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1834/2000\n",
      "\n",
      "Epoch 01834: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1835/2000\n",
      "\n",
      "Epoch 01835: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1836/2000\n",
      "\n",
      "Epoch 01836: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1837/2000\n",
      "\n",
      "Epoch 01837: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1838/2000\n",
      "\n",
      "Epoch 01838: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1839/2000\n",
      "\n",
      "Epoch 01839: LearningRateScheduler reducing learning rate to tf.Tensor(1.5177111e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1840/2000\n",
      "\n",
      "Epoch 01840: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1841/2000\n",
      "\n",
      "Epoch 01841: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1842/2000\n",
      "\n",
      "Epoch 01842: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1843/2000\n",
      "\n",
      "Epoch 01843: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1844/2000\n",
      "\n",
      "Epoch 01844: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1845/2000\n",
      "\n",
      "Epoch 01845: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1846/2000\n",
      "\n",
      "Epoch 01846: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1847/2000\n",
      "\n",
      "Epoch 01847: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1848/2000\n",
      "\n",
      "Epoch 01848: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1849/2000\n",
      "\n",
      "Epoch 01849: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1850/2000\n",
      "\n",
      "Epoch 01850: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1851/2000\n",
      "\n",
      "Epoch 01851: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1852/2000\n",
      "\n",
      "Epoch 01852: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1853/2000\n",
      "\n",
      "Epoch 01853: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1854/2000\n",
      "\n",
      "Epoch 01854: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1855/2000\n",
      "\n",
      "Epoch 01855: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1856/2000\n",
      "\n",
      "Epoch 01856: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1857/2000\n",
      "\n",
      "Epoch 01857: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1858/2000\n",
      "\n",
      "Epoch 01858: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1859/2000\n",
      "\n",
      "Epoch 01859: LearningRateScheduler reducing learning rate to tf.Tensor(1.2141701e-12, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1860/2000\n",
      "\n",
      "Epoch 01860: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1861/2000\n",
      "\n",
      "Epoch 01861: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1862/2000\n",
      "\n",
      "Epoch 01862: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1863/2000\n",
      "\n",
      "Epoch 01863: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1864/2000\n",
      "\n",
      "Epoch 01864: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1865/2000\n",
      "\n",
      "Epoch 01865: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1866/2000\n",
      "\n",
      "Epoch 01866: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1867/2000\n",
      "\n",
      "Epoch 01867: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1868/2000\n",
      "\n",
      "Epoch 01868: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1869/2000\n",
      "\n",
      "Epoch 01869: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1870/2000\n",
      "\n",
      "Epoch 01870: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1871/2000\n",
      "\n",
      "Epoch 01871: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1872/2000\n",
      "\n",
      "Epoch 01872: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1873/2000\n",
      "\n",
      "Epoch 01873: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1874/2000\n",
      "\n",
      "Epoch 01874: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1875/2000\n",
      "\n",
      "Epoch 01875: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1876/2000\n",
      "\n",
      "Epoch 01876: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1877/2000\n",
      "\n",
      "Epoch 01877: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1878/2000\n",
      "\n",
      "Epoch 01878: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1879/2000\n",
      "\n",
      "Epoch 01879: LearningRateScheduler reducing learning rate to tf.Tensor(9.713352e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1880/2000\n",
      "\n",
      "Epoch 01880: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1881/2000\n",
      "\n",
      "Epoch 01881: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1882/2000\n",
      "\n",
      "Epoch 01882: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1883/2000\n",
      "\n",
      "Epoch 01883: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1884/2000\n",
      "\n",
      "Epoch 01884: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1885/2000\n",
      "\n",
      "Epoch 01885: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1886/2000\n",
      "\n",
      "Epoch 01886: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1887/2000\n",
      "\n",
      "Epoch 01887: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1888/2000\n",
      "\n",
      "Epoch 01888: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1889/2000\n",
      "\n",
      "Epoch 01889: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1890/2000\n",
      "\n",
      "Epoch 01890: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1891/2000\n",
      "\n",
      "Epoch 01891: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1892/2000\n",
      "\n",
      "Epoch 01892: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1893/2000\n",
      "\n",
      "Epoch 01893: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1894/2000\n",
      "\n",
      "Epoch 01894: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1895/2000\n",
      "\n",
      "Epoch 01895: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1896/2000\n",
      "\n",
      "Epoch 01896: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1897/2000\n",
      "\n",
      "Epoch 01897: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1898/2000\n",
      "\n",
      "Epoch 01898: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1899/2000\n",
      "\n",
      "Epoch 01899: LearningRateScheduler reducing learning rate to tf.Tensor(7.7706895e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1900/2000\n",
      "\n",
      "Epoch 01900: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1901/2000\n",
      "\n",
      "Epoch 01901: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1902/2000\n",
      "\n",
      "Epoch 01902: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1903/2000\n",
      "\n",
      "Epoch 01903: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1904/2000\n",
      "\n",
      "Epoch 01904: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1905/2000\n",
      "\n",
      "Epoch 01905: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1906/2000\n",
      "\n",
      "Epoch 01906: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1907/2000\n",
      "\n",
      "Epoch 01907: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1908/2000\n",
      "\n",
      "Epoch 01908: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1909/2000\n",
      "\n",
      "Epoch 01909: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1910/2000\n",
      "\n",
      "Epoch 01910: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1911/2000\n",
      "\n",
      "Epoch 01911: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1912/2000\n",
      "\n",
      "Epoch 01912: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1913/2000\n",
      "\n",
      "Epoch 01913: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1914/2000\n",
      "\n",
      "Epoch 01914: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1915/2000\n",
      "\n",
      "Epoch 01915: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1916/2000\n",
      "\n",
      "Epoch 01916: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1917/2000\n",
      "\n",
      "Epoch 01917: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1918/2000\n",
      "\n",
      "Epoch 01918: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1919/2000\n",
      "\n",
      "Epoch 01919: LearningRateScheduler reducing learning rate to tf.Tensor(6.216546e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1920/2000\n",
      "\n",
      "Epoch 01920: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1921/2000\n",
      "\n",
      "Epoch 01921: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1922/2000\n",
      "\n",
      "Epoch 01922: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1923/2000\n",
      "\n",
      "Epoch 01923: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1924/2000\n",
      "\n",
      "Epoch 01924: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1925/2000\n",
      "\n",
      "Epoch 01925: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1926/2000\n",
      "\n",
      "Epoch 01926: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1927/2000\n",
      "\n",
      "Epoch 01927: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1928/2000\n",
      "\n",
      "Epoch 01928: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1929/2000\n",
      "\n",
      "Epoch 01929: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1930/2000\n",
      "\n",
      "Epoch 01930: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1931/2000\n",
      "\n",
      "Epoch 01931: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1932/2000\n",
      "\n",
      "Epoch 01932: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1933/2000\n",
      "\n",
      "Epoch 01933: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1934/2000\n",
      "\n",
      "Epoch 01934: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1935/2000\n",
      "\n",
      "Epoch 01935: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1936/2000\n",
      "\n",
      "Epoch 01936: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1937/2000\n",
      "\n",
      "Epoch 01937: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1938/2000\n",
      "\n",
      "Epoch 01938: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1939/2000\n",
      "\n",
      "Epoch 01939: LearningRateScheduler reducing learning rate to tf.Tensor(4.973242e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1940/2000\n",
      "\n",
      "Epoch 01940: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1941/2000\n",
      "\n",
      "Epoch 01941: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1942/2000\n",
      "\n",
      "Epoch 01942: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1943/2000\n",
      "\n",
      "Epoch 01943: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1944/2000\n",
      "\n",
      "Epoch 01944: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1945/2000\n",
      "\n",
      "Epoch 01945: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1946/2000\n",
      "\n",
      "Epoch 01946: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1947/2000\n",
      "\n",
      "Epoch 01947: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1948/2000\n",
      "\n",
      "Epoch 01948: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1949/2000\n",
      "\n",
      "Epoch 01949: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1950/2000\n",
      "\n",
      "Epoch 01950: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1951/2000\n",
      "\n",
      "Epoch 01951: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1952/2000\n",
      "\n",
      "Epoch 01952: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1953/2000\n",
      "\n",
      "Epoch 01953: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1954/2000\n",
      "\n",
      "Epoch 01954: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1955/2000\n",
      "\n",
      "Epoch 01955: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1956/2000\n",
      "\n",
      "Epoch 01956: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1957/2000\n",
      "\n",
      "Epoch 01957: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1958/2000\n",
      "\n",
      "Epoch 01958: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1959/2000\n",
      "\n",
      "Epoch 01959: LearningRateScheduler reducing learning rate to tf.Tensor(3.9785902e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1960/2000\n",
      "\n",
      "Epoch 01960: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.775 - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1961/2000\n",
      "\n",
      "Epoch 01961: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1962/2000\n",
      "\n",
      "Epoch 01962: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1963/2000\n",
      "\n",
      "Epoch 01963: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1964/2000\n",
      "\n",
      "Epoch 01964: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1965/2000\n",
      "\n",
      "Epoch 01965: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1966/2000\n",
      "\n",
      "Epoch 01966: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1967/2000\n",
      "\n",
      "Epoch 01967: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1968/2000\n",
      "\n",
      "Epoch 01968: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1969/2000\n",
      "\n",
      "Epoch 01969: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1970/2000\n",
      "\n",
      "Epoch 01970: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1971/2000\n",
      "\n",
      "Epoch 01971: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1972/2000\n",
      "\n",
      "Epoch 01972: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1973/2000\n",
      "\n",
      "Epoch 01973: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1974/2000\n",
      "\n",
      "Epoch 01974: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1975/2000\n",
      "\n",
      "Epoch 01975: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1976/2000\n",
      "\n",
      "Epoch 01976: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1977/2000\n",
      "\n",
      "Epoch 01977: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1978/2000\n",
      "\n",
      "Epoch 01978: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1979/2000\n",
      "\n",
      "Epoch 01979: LearningRateScheduler reducing learning rate to tf.Tensor(3.1828752e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1980/2000\n",
      "\n",
      "Epoch 01980: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1981/2000\n",
      "\n",
      "Epoch 01981: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1982/2000\n",
      "\n",
      "Epoch 01982: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1983/2000\n",
      "\n",
      "Epoch 01983: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1984/2000\n",
      "\n",
      "Epoch 01984: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1985/2000\n",
      "\n",
      "Epoch 01985: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1986/2000\n",
      "\n",
      "Epoch 01986: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1987/2000\n",
      "\n",
      "Epoch 01987: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1988/2000\n",
      "\n",
      "Epoch 01988: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1989/2000\n",
      "\n",
      "Epoch 01989: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1990/2000\n",
      "\n",
      "Epoch 01990: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1991/2000\n",
      "\n",
      "Epoch 01991: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1992/2000\n",
      "\n",
      "Epoch 01992: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1993/2000\n",
      "\n",
      "Epoch 01993: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1994/2000\n",
      "\n",
      "Epoch 01994: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1995/2000\n",
      "\n",
      "Epoch 01995: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1996/2000\n",
      "\n",
      "Epoch 01996: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1997/2000\n",
      "\n",
      "Epoch 01997: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1998/2000\n",
      "\n",
      "Epoch 01998: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 1999/2000\n",
      "\n",
      "Epoch 01999: LearningRateScheduler reducing learning rate to tf.Tensor(2.546298e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.7755 - val_loss: 3.4714\n",
      "Epoch 2000/2000\n",
      "\n",
      "Epoch 02000: LearningRateScheduler reducing learning rate to tf.Tensor(2.0370405e-13, shape=(), dtype=float32).\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.7755 - val_loss: 3.4714\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"MSE\", optimizer=SGD(learning_rate=1e-4))\n",
    "# batch_size = 32\n",
    "batch_size = X_train.shape[0]\n",
    "history = model.fit(\n",
    "    epochs=2000,\n",
    "    batch_size=batch_size,\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[lr_schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_loss, val_loss = history.history['loss'], history.history['val_loss']\n",
    "\n",
    "plt.title('Loss')\n",
    "plt.plot(training_loss, label='Train')\n",
    "plt.plot(val_loss, label='Val')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999391606330861"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(df[:,:-1])\n",
    "y_true = df[:,-1]\n",
    "r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_gap = 2.5\n",
    "x_query = np.linspace(0, 10, 100)\n",
    "x_query = [[v, query_gap] for v in x_query]\n",
    "x_query = np.array(x_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_query.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_query = model.predict(x_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x_query[:,0], y_query)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'{LC}-VT.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "path = '../notebooks/'+ f'{LC}-VT.h5'\n",
    "model = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(x_query, columns=[\"Vop\", \"cell gap\"])\n",
    "result_df[\"T%\"] = y_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-22-12-54-53\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"LC\": \"LCT-19-580, MOX-1\",\n",
    "    \"cell_gap\": \"2.5, 2.1\",\n",
    "    \"V_max\": \"10.0, 10.0\",\n",
    "    \"V_min\": \"2.0, 2.0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = {}\n",
    "for k, v in params.items():\n",
    "    new_params[k] = v.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LC': ['LCT-19-580', ' MOX-1'],\n",
       " 'cell_gap': ['2.5', ' 2.1'],\n",
       " 'V_max': ['10.0', ' 10.0'],\n",
       " 'V_min': ['2.0', ' 2.0']}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
